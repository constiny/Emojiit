{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data\n",
    "--------------\n",
    "## first check the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18866900 data/emojitweets-01-04-2018.txt\n"
     ]
    }
   ],
   "source": [
    "# check how many lines\n",
    "! wc -l data/emojitweets-01-04-2018.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209430000 data/emojitweets-01-04-2018.txt\n"
     ]
    }
   ],
   "source": [
    "# check how many words\n",
    "! wc -w data/emojitweets-01-04-2018.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.100392751326398"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On average the sentense are have 11 words\n",
    "209430000/18866900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - test - validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15093520.0, 1886690.0, 3773380.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split on 80-10-10\n",
    "18866900 * 0.8, 18866900 * 0.1, 18866900 * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -15093520 data/emojitweets-01-04-2018.txt >>emoji_train.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail: error writing 'standard output': Broken pipe\n"
     ]
    }
   ],
   "source": [
    "! (tail -3773380 data/emojitweets-01-04-2018.txt | head -1886690) >> emoji_val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -1886690 data/emojitweets-01-04-2018.txt >> emoji_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate small_sample\n",
    "! head -1509352 data/emoji_train.txt >> data/emoji_ss.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to generate word vectors using Word2Vec \n",
    "  \n",
    "# importing all necessary modules \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "  \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "  \n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import emoji\n",
    "import regex\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = open(\"emoji_1M.txt\", \"r\") \n",
    "sample = open(\"data/emoji_ss.txt\", \"r\") \n",
    "s = sample.read() \n",
    "  \n",
    "# Replaces escape character with space \n",
    "f = s.replace(\"\\n\", \" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Squad arriving for Game 2 ğŸš€\\nDude is like 5â€™8 140 pounds his dick was long and strong(always the little dudes carrying the ğŸ†) \\U0001f92ağŸ™ƒ\\nFOLLOWERSğŸ‘‡\\nI CANT BREATIUHW ğŸ’€ğŸ’€ğŸ’€\\n2ï¸âƒ£4ï¸âƒ£ hours 'til our schedule drops!\\nNEW || Zach &amp; Jack at Limelight tonight! (April 17) Â©ï¸nvmbesson\\nIâ€™m live at Milk Boy studio the home of  making some hits ğŸ’ªğŸ¾\\nI am SO scared of birdsğŸ¤§\\nThatâ€™s me ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\\nMy heart is so full rn ğŸ’–ğŸ’–\\nThis is one of my favorite songs to sing in this episode â¤ï¸\\nTook my goat to get groomed for the first tim\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = open(\"emoji_1M.txt\", \"r\") \n",
    "sample = open(\"emoji_ss.txt\", \"r\") \n",
    "s = sample.read() \n",
    "  \n",
    "# Replaces escape character with space \n",
    "# f = s.replace(\"\\n\", \" \") \n",
    "f = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all \n",
    "notes = [\",\", \".\", \"/'\", \"(\" ,\")\", \"'\", '/\"', \":\", \";\", \"/\", \"(\", \")\", \"â€œ\", \"â€\", \"-\", \"+\", \"#\", \"â€¦\", \"!\"]\n",
    "for note in notes:\n",
    "    f = f.replace(note, \"\")\n",
    "  \n",
    "data = [] \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84618238"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to helper\n",
    "def split_count(text):\n",
    "\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X', text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "\n",
    "    return emoji_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = f_ss\n",
    "# iterate through each sentence in the file \n",
    "for i in sent_tokenize(f): \n",
    "    temp = [] \n",
    "      \n",
    "    # tokenize the sentence into words \n",
    "    for j in word_tokenize(i): \n",
    "        temp.append(j.lower()) \n",
    "  \n",
    "    data.append(temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "# remove stop words and snowball stemmer\n",
    "out = [[word for word in words if word not in stop] for words in data]\n",
    "snowball = SnowballStemmer('english')\n",
    "docs_snowball = [[snowball.stem(word) for word in words] for words in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79777"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_snowball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_snowball[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save emoji list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4358"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emoji_list = list(emoji_set)\n",
    "# with open(\"emoji_list.csv\", 'w', newline='') as myfile:\n",
    "#      w = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "#      w.writerow(emoji_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"emoji_list.csv\", 'r', newline='') as myfile:\n",
    "#      emoji_list = csv.reader(myfile, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CBOW model \n",
    "model1 = gensim.models.Word2Vec(data, \n",
    "                                min_count = 10,  \n",
    "                                size = 300, \n",
    "                                window = 16,\n",
    "                                workers= 8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CBOW model\n",
    "import pickle\n",
    "with open('cbow_ss.pkl', 'wb') as f:\n",
    "    pickle.dump(model1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab': 19961500,\n",
       " 'vectors': 31938400,\n",
       " 'syn1neg': 31938400,\n",
       " 'total': 83838300}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(\"data/emoji_val.2csv\",index_col=0)\n",
    "emoji_list = val_df[\"emoji\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to helper\n",
    "def emoji_prodictor(word, model):\n",
    "    sim = model.most_similar(word,topn=75)\n",
    "    for i in sim:\n",
    "        if i[0] in emoji_list:\n",
    "            return i[0]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['let', 'go', 'groceri', 'buy', 'appl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move to helper\n",
    "def word_pipeline(sentense):\n",
    "    out = [word for word in sentense.lower().split(\" \") if word not in stop]\n",
    "    out = [snowball.stem(word) for word in out]\n",
    "    return out\n",
    "    \n",
    "    \n",
    "s1 = \"let's go grocery and buy some apple\"\n",
    "word_pipeline(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤·â€â™€ï¸\n",
      "ğŸ¤¦ğŸ¾â€â™€ï¸\n",
      "ğŸ›’\n",
      "ğŸ’¸\n",
      "ğŸ‘ğŸ½\n"
     ]
    }
   ],
   "source": [
    "s1 = \"let's go grocery and buy some apple\"\n",
    "for w in word_pipeline(s1):\n",
    "    print(emoji_prodictor(w, model1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸ‘ŒğŸ¼'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_prodictor(\"today\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create skip-gram model \n",
    "model2 = gensim.models.Word2Vec(data, \n",
    "                                min_count = 10,  \n",
    "                                size = 300, \n",
    "                                window = 16,\n",
    "                                sg = 1,\n",
    "                                workers=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save skip-gram model\n",
    "import pickle\n",
    "with open('sg_ss.pkl', 'wb') as f:\n",
    "    pickle.dump(model2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜‚\n",
      "ğŸ˜‚\n",
      "ğŸ˜€\n",
      "buy\n",
      "ğŸ\n"
     ]
    }
   ],
   "source": [
    "s1 = \"let's go grocery and buy some apples\"\n",
    "for w in word_pipeline(s1):\n",
    "    print(emoji_prodictor(w, model2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nowğŸ®', 0.7763185501098633),\n",
       " ('puzzl', 0.7215666770935059),\n",
       " ('now~ğŸ®', 0.6516302227973938),\n",
       " ('onğŸ’¡', 0.6338413953781128),\n",
       " ('app', 0.6186978816986084),\n",
       " ('allğŸ˜†', 0.5676931738853455),\n",
       " ('â—ï¸freeâ—ï¸', 0.5613607168197632),\n",
       " ('nowâ€¼ï¸dino', 0.5496898293495178),\n",
       " ('microphon', 0.5196519494056702),\n",
       " ('goâ€¼ï¸', 0.5183366537094116),\n",
       " ('ğŸ°', 0.5135799646377563),\n",
       " ('â€¼ï¸brand', 0.508499026298523),\n",
       " ('store', 0.5015548467636108),\n",
       " ('iiv', 0.47544899582862854),\n",
       " ('availableâ€¼ï¸', 0.4744521677494049),\n",
       " ('ğŸ™‹', 0.45962515473365784),\n",
       " ('ğŸ˜âœ¨', 0.4565337300300598),\n",
       " ('star', 0.4419368803501129),\n",
       " ('apk', 0.4328591525554657),\n",
       " ('dailymot', 0.4285903573036194)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(\"googl\",topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ground-truth\n",
    "with open('val_dict2.pickle', 'rb') as handle:\n",
    "    val_dict = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define score function with stemmer and trim stop words\n",
    "# def word2vec_score(val_dict, model):\n",
    "#     total_words = 0\n",
    "#     total_predicts = 0\n",
    "#     correct = 0\n",
    "#     words = []\n",
    "#     word_vectors = model.wv\n",
    "#     for word in val_dict:\n",
    "# #         print(word)\n",
    "#         if word_pipeline(word):\n",
    "#             w = word_pipeline(word)[0]\n",
    "#             words.append(w)\n",
    "#             if w in word_vectors:\n",
    "#                 total_words += 1\n",
    "#                 if emoji_prodictor(w, model) in val_dict[word]:\n",
    "#                     correct += 1\n",
    "#                     total_predicts += 1\n",
    "#                 elif emoji_prodictor(w, model) in emoji_set:\n",
    "#                     total_predicts += 1\n",
    "#     return correct/total_words, correct/total_predicts, words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define score function \n",
    "def word2vec_score(val_dict, model):\n",
    "    total_words = 0\n",
    "    total_predicts = 0\n",
    "    correct = 0\n",
    "    words = []\n",
    "    word_vectors = model.wv\n",
    "    for word in val_dict:\n",
    "#         print(word)\n",
    "        if word:\n",
    "            w = word.lower()\n",
    "            words.append(w)\n",
    "            if w in word_vectors:\n",
    "                total_words += 1\n",
    "                if emoji_prodictor(w, model) in val_dict[word]:\n",
    "                    correct += 1\n",
    "                    total_predicts += 1\n",
    "                elif emoji_prodictor(w, model) in emoji_set:\n",
    "                    total_predicts += 1\n",
    "    return correct/total_words, correct/total_predicts, words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = word2vec_score(val_dict, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = word2vec_score(val_dict, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline for ss, 0.04464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'linked',\n",
       " 'Slovakia',\n",
       " 'crying',\n",
       " '30',\n",
       " 'eleven',\n",
       " 'thirty',\n",
       " 'turban',\n",
       " 'ball',\n",
       " 'Miquelon',\n",
       " 'machine',\n",
       " 'trumpet',\n",
       " 'Libra',\n",
       " 'Austria',\n",
       " 'Costa',\n",
       " 'potted',\n",
       " 'sloth',\n",
       " 'Nauru',\n",
       " 'lock',\n",
       " 'lion']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(val_dict.keys())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_weighted_score(val_dict, model,emoji_frequency):\n",
    "    total_words = 0\n",
    "    total_weighted = 0\n",
    "    correct_weighted = 0\n",
    "#     words = []\n",
    "    word_vectors = model.wv\n",
    "    for word in val_dict:\n",
    "        if word_pipeline(word):\n",
    "            w = word_pipeline(word)[0]\n",
    "#             words.append(w)\n",
    "            if w in word_vectors:\n",
    "                total_words += 1\n",
    "                prediction = emoji_prodictor(w, model)\n",
    "                if prediction in val_dict[word]:\n",
    "                    correct_weighted += emoji_frequency[prediction]\n",
    "                    total_weighted += emoji_frequency[prediction]\n",
    "                elif prediction in emoji_set:\n",
    "                    total_weighted += emoji_frequency[prediction]\n",
    "    return correct_weighted/total_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.256142944437114"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model1, emoji_frequency)    # CBOW good at predicting more frequent word (high weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09182329105692395"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model2, emoji_frequency)    # Skip-gram good at predicting less frequent word (low weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new predictor with higher requirement to predict\n",
    "def emoji_prodictor(word, model):\n",
    "    sim = model.most_similar(word,topn=40)\n",
    "    for i in sim:\n",
    "        if i[0] in emoji_list and i[1] >= 0.55:\n",
    "            return i[0]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = word2vec_score(val_dict, model1)\n",
    "score2 = word2vec_score(val_dict, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.08711885500933417, 0.5072463768115942),\n",
       " (0.06782825140012445, 0.5647668393782384))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16 and new notes / predictor sim>=0.55\n",
    "# We can see improvement on accuracy but a drop in coverage\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5681407491990289"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model1, emoji_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12596177586164578"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model2, emoji_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "Model tuning history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.1630012936610608, 0.2202797202797203),\n",
       " (0.21798188874514876, 0.27897350993377484))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16 and no stemmer\n",
    "# Looks like stemmer does not help much\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.256142944437114"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16 and new notes\n",
    "word2vec_weighted_score(val_dict, model1, emoji_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09182329105692395"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model2, emoji_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16490354698195395, 0.19188993482983346),\n",
       " (0.22028624766645924, 0.2512420156139106))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16 and new notes\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16936488169364883, 0.19470293486041518),\n",
       " (0.22478206724782068, 0.2565742714996446))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16 and new notes\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16084788029925187, 0.19068736141906872),\n",
       " (0.21571072319201995, 0.25181950509461426))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.15149625935162095, 0.17711370262390672),\n",
       " (0.21571072319201995, 0.24162011173184358))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 20\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.1589775561097257, 0.19480519480519481),\n",
       " (0.18952618453865336, 0.22943396226415094))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 150, window = 10\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.17206982543640897, 0.21052631578947367),\n",
       " (0.2013715710723192, 0.2492283950617284))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 10\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16521197007481297, 0.1990984222389181),\n",
       " (0.20199501246882792, 0.2577565632458234))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 500, window = 10\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16390532544378697, 0.22124600638977635),\n",
       " (0.17810650887573964, 0.2872137404580153))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 5,  size = 500, window = 8\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16209476309226933, 0.19667170953101362),\n",
       " (0.19887780548628428, 0.2570507655116841))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 500, window = 8\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.14526184538653367, 0.19082719082719082),\n",
       " (0.1502493765586035, 0.21929026387625114))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 500, window = 3\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.14964788732394366, 0.18695014662756598),\n",
       " (0.15307262569832403, 0.23539518900343642))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # score for CBOW and skipgram for small sample with SnowballStemmer\n",
    "# score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ğŸ˜€',\n",
       " 'ğŸ˜˜',\n",
       " 'ğŸ˜‘',\n",
       " 'ğŸ˜µ',\n",
       " 'ğŸ˜­',\n",
       " 'ğŸ‘¹',\n",
       " 'ğŸ’—',\n",
       " 'ğŸ’¢',\n",
       " 'ğŸ¤šğŸ¿',\n",
       " '\\U0001f90cğŸ¼',\n",
       " 'ğŸ¤˜',\n",
       " 'ğŸ‘†ğŸ½',\n",
       " 'ğŸ‘',\n",
       " 'ğŸ¤œğŸ¿',\n",
       " 'ğŸ™ğŸ»',\n",
       " 'ğŸ’ªğŸ¿',\n",
       " 'ğŸ‘ƒğŸ½',\n",
       " 'ğŸ‘¦ğŸ¾',\n",
       " '\\U0001f9d4ğŸ¾',\n",
       " 'ğŸ‘©ğŸ¾',\n",
       " 'ğŸ‘©ğŸ¾\\u200d\\U0001f9b3',\n",
       " 'ğŸ‘±ğŸ¿\\u200dâ™€ï¸',\n",
       " 'ğŸ‘µğŸ¾',\n",
       " 'ğŸ™ğŸ¿\\u200dâ™€ï¸',\n",
       " 'ğŸ™ğŸ¿\\u200dâ™€ï¸',\n",
       " 'ğŸ™…ğŸ¿\\u200dâ™€ï¸',\n",
       " 'ğŸ™†ğŸ¿\\u200dâ™€ï¸',\n",
       " 'ğŸ’ğŸ¾\\u200dâ™€',\n",
       " 'ğŸ™‹ğŸ¾\\u200dâ™€',\n",
       " '\\U0001f9cfğŸ¾\\u200dâ™€',\n",
       " 'ğŸ™‡ğŸ¾\\u200dâ™€',\n",
       " 'ğŸ¤¦ğŸ¾\\u200dâ™€ï¸',\n",
       " 'ğŸ¤·ğŸ¾\\u200dâ™€ï¸',\n",
       " 'ğŸ‘©ğŸ»\\u200dâš•ï¸',\n",
       " '\\U0001f9d1ğŸ¼\\u200dğŸ«',\n",
       " 'ğŸ‘¨ğŸ»\\u200dâš–ï¸',\n",
       " 'ğŸ‘¨ğŸ¼\\u200dğŸŒ¾',\n",
       " '\\U0001f9d1ğŸ¼\\u200dğŸ”§',\n",
       " 'ğŸ‘©ğŸ¼\\u200dğŸ­',\n",
       " 'ğŸ‘¨ğŸ¼\\u200dğŸ”¬',\n",
       " '\\U0001f9d1ğŸ¼\\u200dğŸ¤',\n",
       " 'ğŸ‘©ğŸ¼\\u200dğŸ¨',\n",
       " 'ğŸ‘©ğŸ»\\u200dâœˆï¸',\n",
       " '\\U0001f9d1ğŸ¼\\u200dğŸš’',\n",
       " 'ğŸ‘®ğŸ¾\\u200dâ™‚ï¸',\n",
       " 'ğŸ•µğŸ¼\\u200dâ™‚',\n",
       " 'ğŸ’‚ğŸ»\\u200dâ™‚',\n",
       " 'ğŸ‘·ğŸ½',\n",
       " 'ğŸ¤´ğŸ½',\n",
       " 'ğŸ‘³ğŸ»\\u200dâ™€',\n",
       " 'ğŸ¤µğŸ»\\u200dâ™‚',\n",
       " 'ğŸ‘°ğŸ»\\u200dâ™‚',\n",
       " '\\U0001f931ğŸ½',\n",
       " 'ğŸ…ğŸ½',\n",
       " '\\U0001f9b8ğŸ¾\\u200dâ™‚',\n",
       " '\\U0001f9b9ğŸ¾\\u200dâ™‚',\n",
       " '\\U0001f9d9ğŸ¾\\u200dâ™‚',\n",
       " '\\U0001f9dağŸ¾\\u200dâ™‚',\n",
       " '\\U0001f9dbğŸ¾\\u200dâ™‚',\n",
       " '\\U0001f9dcğŸ¾\\u200dâ™‚',\n",
       " '\\U0001f9ddğŸ¾\\u200dâ™‚',\n",
       " 'ğŸ’†ğŸ¿',\n",
       " 'ğŸ’‡ğŸ¿',\n",
       " 'ğŸš¶ğŸ¿',\n",
       " '\\U0001f9cdğŸ¿',\n",
       " '\\U0001f9ceğŸ¿',\n",
       " '\\U0001f9d1ğŸ¿\\u200d\\U0001f9af',\n",
       " 'ğŸ‘©ğŸ¿\\u200d\\U0001f9bc',\n",
       " 'ğŸƒğŸ¼\\u200dâ™‚',\n",
       " 'ğŸ•ºğŸ¿',\n",
       " '\\U0001f9d6ğŸ¿\\u200dâ™‚',\n",
       " '\\U0001f9d7ğŸ¿\\u200dâ™‚',\n",
       " 'ğŸŒğŸ»',\n",
       " 'ğŸŒğŸ¾\\u200dâ™€',\n",
       " 'ğŸ„ğŸ¾\\u200dâ™€',\n",
       " 'ğŸš£ğŸ¾\\u200dâ™€',\n",
       " 'ğŸŠğŸ¾\\u200dâ™€',\n",
       " 'â›¹ğŸ¼\\u200dâ™€ï¸',\n",
       " 'ğŸ‹\\u200dâ™€ï¸',\n",
       " 'ğŸš´ğŸ¿\\u200dâ™‚',\n",
       " 'ğŸšµğŸ¿\\u200dâ™‚',\n",
       " 'ğŸ¤¸ğŸ¿\\u200dâ™‚',\n",
       " 'ğŸ¤½ğŸ½\\u200dâ™‚ï¸',\n",
       " 'ğŸ¤¾ğŸ½\\u200dâ™‚ï¸',\n",
       " 'ğŸ¤¹ğŸ½\\u200dâ™‚ï¸',\n",
       " '\\U0001f9d8ğŸ½\\u200dâ™‚ï¸',\n",
       " '\\U0001f9d1\\u200dğŸ¤\\u200d\\U0001f9d1',\n",
       " 'ğŸ‘©ğŸ»\\u200dğŸ¤\\u200dğŸ‘©ğŸ¾',\n",
       " 'ğŸ‘©ğŸ¼\\u200dğŸ¤\\u200dğŸ‘¨ğŸ½',\n",
       " 'ğŸ‘¨ğŸ½\\u200dğŸ¤\\u200dğŸ‘¨ğŸ¼',\n",
       " 'ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§',\n",
       " 'ğŸ»',\n",
       " 'ğŸ¦„',\n",
       " 'ğŸ¿',\n",
       " '\\U0001fab6',\n",
       " '\\U0001f997',\n",
       " 'ğŸŒµ',\n",
       " 'ğŸ¥”',\n",
       " 'ğŸŒ­',\n",
       " '\\U0001f96e',\n",
       " 'ğŸ¾',\n",
       " 'â›°ï¸',\n",
       " 'ğŸ¢',\n",
       " 'ğŸŒ…',\n",
       " 'ğŸš”',\n",
       " 'ğŸš¨',\n",
       " 'ğŸ›°',\n",
       " 'ğŸ•–',\n",
       " 'ğŸŒŸ',\n",
       " 'â˜‚',\n",
       " 'ğŸ',\n",
       " 'ğŸ‘',\n",
       " '\\U0001f9f8',\n",
       " '\\U0001f97c',\n",
       " '\\U0001fa70',\n",
       " 'ğŸšï¸',\n",
       " 'âŒ¨ï¸',\n",
       " '\\U0001fa94',\n",
       " 'âœ‰ï¸',\n",
       " 'ğŸ“‚',\n",
       " 'ğŸ”“',\n",
       " 'ğŸ—œï¸',\n",
       " 'ğŸ›',\n",
       " 'ğŸš®',\n",
       " 'â†—ï¸',\n",
       " 'ğŸ”›',\n",
       " 'â™',\n",
       " 'â¹',\n",
       " 'â•',\n",
       " 'âœ³',\n",
       " '6âƒ£',\n",
       " 'ğŸ†—',\n",
       " '\\U0001f7e2',\n",
       " 'ğŸ”»',\n",
       " 'ğŸ‡¦ğŸ‡¸',\n",
       " 'ğŸ‡¨ğŸ‡«',\n",
       " 'ğŸ‡ªğŸ‡¸',\n",
       " 'ğŸ‡­ğŸ‡³',\n",
       " 'ğŸ‡±ğŸ‡¦',\n",
       " 'ğŸ‡²ğŸ‡¼',\n",
       " 'ğŸ‡µğŸ‡¾',\n",
       " 'ğŸ‡¹ğŸ‡©',\n",
       " 'ğŸ‡¼ğŸ‡¸']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_list[::30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word frequency\n",
    "c = Counter(f.split(\" \"))\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emoji_freq\n",
    "emoji_frequency = {}\n",
    "\n",
    "total = 0\n",
    "for emoji in emoji_list:\n",
    "    emoji_frequency[emoji] = c[emoji]\n",
    "    total += c[emoji]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_frequency2 = {}\n",
    "for key, value in emoji_frequency.items():\n",
    "    emoji_frequency2[key] = value/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_freq = {k: v for k, v in sorted(emoji_frequency.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04464584326015571"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "69149/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ğŸ˜‚': 69149,\n",
       " 'ğŸ”¥': 33328,\n",
       " 'â¤ï¸': 27982,\n",
       " 'ğŸ˜­': 25433,\n",
       " 'ğŸ˜': 22820,\n",
       " 'ğŸ‘‰': 17657,\n",
       " 'ğŸ’•': 12445,\n",
       " 'ğŸ˜Š': 12041,\n",
       " 'âœ¨': 11794,\n",
       " 'ğŸ¤”': 10607,\n",
       " 'ğŸ‘€': 10602,\n",
       " 'ğŸ˜©': 10214,\n",
       " 'â¤': 10076,\n",
       " 'ğŸ’œ': 8118,\n",
       " 'ğŸ™„': 7977,\n",
       " 'âœ…': 7664,\n",
       " 'ğŸš¨': 7606,\n",
       " 'ğŸ’¯': 7535,\n",
       " 'ğŸ””': 7372,\n",
       " 'ğŸ’™': 7344,\n",
       " 'ğŸ¤£': 7226,\n",
       " 'ğŸ˜˜': 7138,\n",
       " 'ğŸ’€': 7133,\n",
       " 'ğŸ˜': 6958,\n",
       " 'ğŸ˜‰': 6916,\n",
       " 'ğŸ’': 6611,\n",
       " 'ğŸ™Œ': 6543,\n",
       " 'ğŸ™': 6248,\n",
       " 'Â©': 5899,\n",
       " 'ğŸ‰': 5817,\n",
       " 'ğŸ’–': 5794,\n",
       " 'ğŸ†': 5700,\n",
       " 'ğŸ‘': 5532,\n",
       " 'â™¨ï¸': 5469,\n",
       " 'ğŸ’¥': 5386,\n",
       " 'ğŸ˜': 5300,\n",
       " 'ğŸ“¹': 5130,\n",
       " 'ğŸ™ƒ': 4995,\n",
       " 'ğŸŒ¸': 4923,\n",
       " 'ğŸ˜¢': 4904,\n",
       " 'ğŸ‘': 4892,\n",
       " 'ğŸ“·': 4632,\n",
       " 'ğŸ‡ºğŸ‡¸': 4576,\n",
       " 'ğŸ™ğŸ»': 4513,\n",
       " 'â¡ï¸': 4484,\n",
       " 'ğŸ’›': 4405,\n",
       " 'ğŸ˜³': 4359,\n",
       " 'ğŸ˜…': 4335,\n",
       " 'ğŸ—£': 4264,\n",
       " 'ğŸ‘ˆ': 4138,\n",
       " 'ğŸ¤—': 4078,\n",
       " 'ğŸ¶': 3946,\n",
       " 'ğŸ‘‘': 3906,\n",
       " 'ğŸ˜”': 3883,\n",
       " 'ğŸ’‹': 3846,\n",
       " 'ğŸ’š': 3809,\n",
       " 'ğŸ˜': 3805,\n",
       " 'â˜ºï¸': 3799,\n",
       " 'ğŸ’—': 3671,\n",
       " 'ğŸ“¸': 3641,\n",
       " 'â¬': 3547,\n",
       " 'â™¥ï¸': 3539,\n",
       " 'ğŸ’«': 3525,\n",
       " 'ğŸ”—': 3486,\n",
       " 'ğŸ¤·ğŸ½\\u200dâ™€ï¸': 3421,\n",
       " 'ğŸ’”': 3340,\n",
       " 'ğŸ–¤': 3287,\n",
       " 'ğŸ‘Œ': 3287,\n",
       " 'ğŸ˜Œ': 3283,\n",
       " 'ğŸ’ª': 3282,\n",
       " 'ğŸŒŸ': 3207,\n",
       " 'ğŸ‘‡': 3186,\n",
       " 'ğŸ¥': 3134,\n",
       " 'ğŸ™‚': 3065,\n",
       " 'ğŸ˜’': 3046,\n",
       " 'â¡': 3039,\n",
       " 'ğŸ˜±': 3012,\n",
       " 'âœ”ï¸': 2994,\n",
       " 'ğŸ’': 2985,\n",
       " 'â€¼ï¸': 2970,\n",
       " 'ğŸ”´': 2924,\n",
       " 'ğŸ˜ˆ': 2911,\n",
       " 'ğŸŒ¹': 2831,\n",
       " 'ğŸ¤¦ğŸ½\\u200dâ™€ï¸': 2708,\n",
       " 'ğŸ˜€': 2706,\n",
       " 'â™¥': 2692,\n",
       " 'ğŸ”œ': 2675,\n",
       " 'âš ': 2653,\n",
       " 'ğŸ˜œ': 2625,\n",
       " 'ğŸ˜†': 2619,\n",
       " 'âš¡': 2478,\n",
       " 'â˜€ï¸': 2472,\n",
       " 'ğŸ˜‹': 2409,\n",
       " 'ğŸ˜„': 2404,\n",
       " 'ğŸ’“': 2403,\n",
       " 'ğŸŒ‘': 2402,\n",
       " 'âœ”': 2384,\n",
       " 'ğŸŒ’': 2361,\n",
       " 'ğŸ˜¤': 2345,\n",
       " 'ğŸŒ“': 2339,\n",
       " 'ğŸ¤§': 2314,\n",
       " 'ğŸ°': 2295,\n",
       " '\\U0001f92a': 2237,\n",
       " 'ğŸ': 2169,\n",
       " 'ğŸ“º': 2163,\n",
       " 'ğŸ’˜': 2154,\n",
       " 'ğŸ˜': 2146,\n",
       " 'ğŸ˜¬': 2140,\n",
       " 'ğŸŒ•': 2125,\n",
       " 'âŒ': 2124,\n",
       " 'ğŸ˜ª': 2123,\n",
       " 'ğŸš€': 2115,\n",
       " 'ğŸŒ˜': 2028,\n",
       " 'ğŸŒ–': 2026,\n",
       " 'ğŸŒ—': 2023,\n",
       " 'ğŸŒ”': 2020,\n",
       " 'â°': 1997,\n",
       " 'ğŸŒ': 1985,\n",
       " 'â˜¹ï¸': 1984,\n",
       " 'ğŸ˜‡': 1973,\n",
       " 'ğŸ™ğŸ¾': 1899,\n",
       " 'ğŸ˜': 1851,\n",
       " 'ğŸ˜´': 1843,\n",
       " 'ğŸ’¦': 1843,\n",
       " 'ğŸ™ğŸ½': 1759,\n",
       " 'ğŸ™ˆ': 1735,\n",
       " 'ğŸ£': 1734,\n",
       " 'ğŸŒ': 1725,\n",
       " 'ğŸ“£': 1709,\n",
       " 'ğŸ˜«': 1708,\n",
       " 'âš ï¸': 1707,\n",
       " 'ğŸ¤·ğŸ½\\u200dâ™‚ï¸': 1700,\n",
       " 'ğŸ‘…': 1696,\n",
       " 'ğŸ’°': 1684,\n",
       " 'ğŸ˜•': 1680,\n",
       " 'ğŸ¨': 1658,\n",
       " 'ğŸ‘Š': 1655,\n",
       " 'ğŸŒ': 1635,\n",
       " 'ğŸ¤¤': 1583,\n",
       " 'ğŸ¤·ğŸ¾\\u200dâ™‚ï¸': 1577,\n",
       " 'ğŸŒ»': 1565,\n",
       " 'ğŸ“': 1551,\n",
       " 'ğŸ‘ğŸ»': 1545,\n",
       " 'â¬‡ï¸': 1545,\n",
       " 'ğŸ˜ƒ': 1531,\n",
       " 'ğŸ€': 1485,\n",
       " 'ğŸ—³': 1480,\n",
       " 'ğŸ”¹': 1474,\n",
       " 'ğŸ“¢': 1412,\n",
       " 'ğŸ™ğŸ¼': 1404,\n",
       " 'ğŸ¤·ğŸ¾\\u200dâ™€ï¸': 1392,\n",
       " '\\U0001f929': 1385,\n",
       " 'ğŸ˜‘': 1368,\n",
       " 'Â©ï¸': 1361,\n",
       " 'ğŸ¤·ğŸ»\\u200dâ™€ï¸': 1360,\n",
       " 'ğŸ˜¡': 1351,\n",
       " 'â–¶ï¸': 1337,\n",
       " 'ğŸ™ŒğŸ»': 1330,\n",
       " 'ğŸ‚': 1326,\n",
       " 'ğŸ”’': 1325,\n",
       " 'ğŸ’„': 1310,\n",
       " 'ğŸŒ†': 1307,\n",
       " 'ğŸŒŠ': 1286,\n",
       " 'ğŸ¤¦ğŸ¾\\u200dâ™‚ï¸': 1282,\n",
       " 'ğŸ“': 1281,\n",
       " 'ğŸ‘ğŸ¼': 1259,\n",
       " 'ğŸ¶': 1253,\n",
       " 'â–¶': 1251,\n",
       " 'ğŸ§': 1243,\n",
       " 'ğŸµ': 1236,\n",
       " 'ğŸ˜›': 1233,\n",
       " 'ğŸ¯': 1228,\n",
       " 'ğŸ¤¦ğŸ½\\u200dâ™‚ï¸': 1221,\n",
       " 'ğŸ‘': 1190,\n",
       " 'ğŸ™ŒğŸ¼': 1189,\n",
       " 'âœˆï¸': 1186,\n",
       " 'ğŸ‘ğŸ»': 1157,\n",
       " 'ğŸ¥': 1157,\n",
       " 'âš½': 1149,\n",
       " 'ğŸ˜': 1130,\n",
       " 'ğŸ™ŒğŸ½': 1106,\n",
       " 'ğŸ‘‹': 1105,\n",
       " 'ğŸ¤¦ğŸ¾\\u200dâ™€ï¸': 1092,\n",
       " 'ğŸ˜®': 1089,\n",
       " 'â˜º': 1087,\n",
       " 'ğŸ”˜': 1084,\n",
       " '\\U0001f9d0': 1083,\n",
       " 'ğŸƒ': 1068,\n",
       " 'ğŸ‘ ': 1045,\n",
       " 'ğŸ˜¥': 1042,\n",
       " 'ğŸ˜»': 1036,\n",
       " 'ğŸŒš': 1030,\n",
       " 'ğŸ¤¦ğŸ»\\u200dâ™€ï¸': 1025,\n",
       " '\\U0001f92d': 1003,\n",
       " 'ğŸ‡¬ğŸ‡§': 999,\n",
       " 'ğŸ¤¦ğŸ»\\u200dâ™‚ï¸': 980,\n",
       " '\\U0001f928': 978,\n",
       " 'ğŸ¤·ğŸ»\\u200dâ™‚ï¸': 978,\n",
       " 'ğŸŒˆ': 960,\n",
       " 'ğŸ': 953,\n",
       " 'ğŸ’§': 948,\n",
       " 'ğŸ¬': 943,\n",
       " 'ğŸ’': 942,\n",
       " 'ğŸ˜£': 940,\n",
       " '\\U0001f9e1': 935,\n",
       " 'ğŸ”µ': 934,\n",
       " 'ğŸŒ™': 930,\n",
       " '\\U0001f92b': 923,\n",
       " 'ğŸ™ŒğŸ¾': 919,\n",
       " 'ğŸ˜“': 911,\n",
       " 'ğŸ“Œ': 908,\n",
       " 'ğŸŒ·': 898,\n",
       " 'â–ªï¸': 898,\n",
       " 'ğŸ¤¢': 897,\n",
       " 'â„ï¸': 895,\n",
       " 'â–': 890,\n",
       " 'ğŸˆ': 868,\n",
       " 'ğŸ¯': 864,\n",
       " 'ğŸ’ªğŸ½': 860,\n",
       " 'ğŸ¤·ğŸ¼\\u200dâ™€ï¸': 855,\n",
       " 'â£ï¸': 851,\n",
       " 'ğŸ•‘': 849,\n",
       " 'ğŸ˜š': 846,\n",
       " 'ğŸ‡¨ğŸ‡¦': 844,\n",
       " 'ğŸ‡«ğŸ‡·': 835,\n",
       " 'ğŸ¥€': 833,\n",
       " 'ğŸ’¸': 828,\n",
       " 'ğŸ¦‹': 824,\n",
       " 'ğŸŒ´': 824,\n",
       " 'ğŸ’': 822,\n",
       " 'ğŸ”': 820,\n",
       " 'ğŸ’Œ': 819,\n",
       " 'ğŸ¥‡': 814,\n",
       " 'ğŸ’»': 805,\n",
       " 'ğŸ€': 801,\n",
       " 'â¬‡': 799,\n",
       " 'ğŸ•™': 795,\n",
       " 'ğŸ“ˆ': 789,\n",
       " 'ğŸ¤“': 785,\n",
       " 'ğŸ‘ğŸ½': 783,\n",
       " 'â˜‘ï¸': 777,\n",
       " 'ğŸ®': 775,\n",
       " 'ğŸŒº': 759,\n",
       " '1âƒ£': 757,\n",
       " 'ğŸŠ': 740,\n",
       " 'âœŒï¸': 737,\n",
       " 'ğŸ’¨': 731,\n",
       " 'ğŸ”': 723,\n",
       " 'ğŸ¤˜': 715,\n",
       " 'ğŸ’': 714,\n",
       " 'ğŸ': 709,\n",
       " 'ğŸ‡§ğŸ‡·': 698,\n",
       " 'ğŸ‘ŒğŸ»': 696,\n",
       " 'ğŸ”Š': 694,\n",
       " 'ğŸ˜²': 693,\n",
       " 'ğŸ‡®ğŸ‡¹': 685,\n",
       " 'ğŸŒ¼': 680,\n",
       " 'ğŸ»': 678,\n",
       " 'ğŸ‡ªğŸ‡¸': 676,\n",
       " 'ğŸ¤': 669,\n",
       " 'ğŸ’£': 668,\n",
       " 'ğŸ“²': 667,\n",
       " 'ğŸ¤': 660,\n",
       " 'ğŸŒ¿': 660,\n",
       " 'ğŸ¨': 660,\n",
       " '2âƒ£': 645,\n",
       " 'ğŸ˜¹': 644,\n",
       " '1ï¸âƒ£': 644,\n",
       " 'ğŸ”±': 639,\n",
       " 'ğŸ’ªğŸ¾': 631,\n",
       " 'ğŸ˜¶': 628,\n",
       " 'ğŸ': 620,\n",
       " 'ğŸ’©': 618,\n",
       " 'ğŸ†š': 617,\n",
       " 'ğŸ“»': 610,\n",
       " 'ğŸ’­': 605,\n",
       " 'â³': 603,\n",
       " 'ğŸ‘ğŸ¼': 600,\n",
       " '2ï¸âƒ£': 597,\n",
       " 'â­': 592,\n",
       " 'ğŸ“…': 589,\n",
       " 'ğŸ¤‘': 588,\n",
       " '\\U0001f92f': 586,\n",
       " 'âœŠ': 583,\n",
       " 'ğŸ': 583,\n",
       " 'ğŸ“Š': 579,\n",
       " 'ğŸ”¸': 576,\n",
       " 'ğŸ’Ÿ': 575,\n",
       " 'ğŸ“': 572,\n",
       " 'ğŸ‡©ğŸ‡ª': 572,\n",
       " 'ğŸ‘ŒğŸ¾': 570,\n",
       " 'ğŸ™‹ğŸ»\\u200dâ™€ï¸': 570,\n",
       " 'ğŸŒ': 570,\n",
       " 'ğŸ±': 568,\n",
       " 'ğŸ†’': 567,\n",
       " 'ğŸ™': 564,\n",
       " 'ğŸ’ªğŸ»': 563,\n",
       " 'ğŸŒ±': 563,\n",
       " 'ğŸ´\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f': 562,\n",
       " 'ğŸ»': 561,\n",
       " 'ğŸ¾': 561,\n",
       " 'ğŸ‡®ğŸ‡³': 561,\n",
       " 'ğŸ“±': 560,\n",
       " 'ğŸ“š': 556,\n",
       " '3âƒ£': 554,\n",
       " 'âœˆ': 550,\n",
       " 'ğŸ': 550,\n",
       " 'ğŸ¦„': 548,\n",
       " 'âœŒ': 546,\n",
       " 'ğŸ˜–': 545,\n",
       " 'ğŸ’ƒ': 543,\n",
       " 'ğŸ”„': 540,\n",
       " 'ğŸ¦': 539,\n",
       " 'ğŸ‘ğŸ¾': 532,\n",
       " '4âƒ£': 530,\n",
       " 'ğŸ’¬': 529,\n",
       " 'ğŸ’¤': 527,\n",
       " 'ğŸ¤·\\u200dâ™€ï¸': 526,\n",
       " 'ğŸ‘‰ğŸ»': 523,\n",
       " 'ğŸ’ªğŸ¼': 523,\n",
       " 'â˜': 523,\n",
       " 'ğŸ˜°': 522,\n",
       " 'ğŸ‡°ğŸ‡·': 522,\n",
       " 'ğŸ‘ŒğŸ¼': 517,\n",
       " 'ğŸ‘ğŸ¿': 515,\n",
       " 'ğŸ‡¿ğŸ‡¦': 514,\n",
       " 'ğŸ‘‡ğŸ»': 513,\n",
       " 'ğŸ’': 513,\n",
       " '\\U0001f92c': 512,\n",
       " 'ğŸ˜¯': 509,\n",
       " 'ğŸ¤·\\u200dâ™‚ï¸': 509,\n",
       " 'ğŸ‡¯ğŸ‡µ': 507,\n",
       " 'ğŸ‘»': 505,\n",
       " 'ğŸ‡¦ğŸ‡·': 501,\n",
       " 'ğŸ‘‹ğŸ»': 500,\n",
       " 'ğŸ¤ ': 491,\n",
       " 'ğŸ‘ŒğŸ½': 488,\n",
       " 'ğŸ‡¦ğŸ‡«': 484,\n",
       " 'ğŸ˜µ': 477,\n",
       " 'ğŸ™Š': 475,\n",
       " 'ğŸ€': 474,\n",
       " 'â©': 474,\n",
       " '3ï¸âƒ£': 472,\n",
       " 'ğŸ‡µğŸ‡­': 469,\n",
       " 'ğŸ•°ï¸': 467,\n",
       " 'ğŸ¤•': 466,\n",
       " '\\U0001f92e': 466,\n",
       " 'ğŸ‡²ğŸ‡½': 460,\n",
       " 'â˜˜ï¸': 455,\n",
       " 'â˜ï¸': 455,\n",
       " 'ğŸ¤': 449,\n",
       " 'ğŸ¼': 446,\n",
       " 'ğŸ˜·': 444,\n",
       " 'ğŸ¤–': 440,\n",
       " 'ğŸš«': 439,\n",
       " 'ğŸ¤¦ğŸ¼\\u200dâ™€ï¸': 435,\n",
       " 'ğŸŒ€': 434,\n",
       " 'ğŸ¥‚': 433,\n",
       " 'ğŸ‘‡ğŸ¼': 432,\n",
       " 'ğŸ¤ğŸ½': 427,\n",
       " 'ğŸ“': 427,\n",
       " 'ğŸ¤¦\\u200dâ™‚ï¸': 420,\n",
       " 'ğŸ“†': 420,\n",
       " 'âœŠğŸ¾': 415,\n",
       " 'ğŸ“°': 412,\n",
       " 'ğŸ”½': 411,\n",
       " 'ğŸ•Š': 405,\n",
       " 'ğŸ¤¡': 403,\n",
       " 'ğŸ¸': 403,\n",
       " 'ğŸ”®': 401,\n",
       " 'ğŸ“': 401,\n",
       " 'ğŸš®': 398,\n",
       " 'ğŸ¯': 396,\n",
       " 'â˜‘': 396,\n",
       " 'ğŸ˜ ': 395,\n",
       " 'âœ‹': 395,\n",
       " 'ğŸ—“': 391,\n",
       " 'ğŸ˜¨': 390,\n",
       " 'â™»ï¸': 390,\n",
       " 'ğŸ‘ŠğŸ»': 389,\n",
       " 'ğŸ“½ï¸': 388,\n",
       " 'â˜ï¸': 385,\n",
       " 'ğŸ•': 385,\n",
       " 'ğŸ¤': 380,\n",
       " 'ğŸ–¥ï¸': 377,\n",
       " 'ğŸ‘†': 376,\n",
       " 'ğŸº': 375,\n",
       " 'ğŸ”›': 375,\n",
       " 'ğŸ†•': 373,\n",
       " 'â˜ ï¸': 370,\n",
       " 'ğŸ”‘': 370,\n",
       " 'ğŸ’¡': 369,\n",
       " 'ğŸ˜™': 364,\n",
       " 'ğŸ ': 364,\n",
       " 'ğŸ¡': 362,\n",
       " 'ğŸ¤ğŸ¾': 359,\n",
       " 'â¤µï¸': 358,\n",
       " 'ğŸ‡®ğŸ‡©': 358,\n",
       " 'ğŸ’ğŸ»\\u200dâ™€ï¸': 356,\n",
       " 'ğŸ‡': 355,\n",
       " 'ğŸ‡¦ğŸ‡º': 355,\n",
       " 'â†ª': 354,\n",
       " 'ğŸ­': 348,\n",
       " 'ğŸ†': 345,\n",
       " 'ğŸ•º': 344,\n",
       " 'ğŸ¦…': 344,\n",
       " 'ğŸ‡µğŸ‡·': 344,\n",
       " 'ğŸ‡³ğŸ‡¬': 343,\n",
       " 'ğŸ‡§ğŸ‡­': 340,\n",
       " 'ğŸ·': 339,\n",
       " 'â–ª': 339,\n",
       " 'ğŸ’': 338,\n",
       " 'âœŒğŸ»': 337,\n",
       " 'ğŸ‘': 337,\n",
       " 'ğŸ«': 335,\n",
       " 'ğŸƒ\\u200dâ™€ï¸': 330,\n",
       " 'ğŸ’¿': 329,\n",
       " 'ğŸ“–': 326,\n",
       " 'ğŸ‡ªğŸ‡¬': 324,\n",
       " 'ğŸ¤™': 323,\n",
       " 'ğŸ”†': 321,\n",
       " 'ğŸ‘½': 320,\n",
       " 'ğŸ˜': 315,\n",
       " 'ğŸ¥Š': 314,\n",
       " 'ğŸ˜—': 313,\n",
       " 'ğŸ': 312,\n",
       " 'ğŸ‘™': 312,\n",
       " 'â˜€': 311,\n",
       " 'ğŸ”': 310,\n",
       " 'ğŸŒŒ': 309,\n",
       " 'ğŸˆ': 307,\n",
       " 'ğŸ¤·ğŸ¼\\u200dâ™‚ï¸': 306,\n",
       " 'ğŸ‘¶': 305,\n",
       " 'ğŸ‘‰ğŸ¼': 304,\n",
       " 'ğŸ‘': 304,\n",
       " 'ğŸ‡¨ğŸ‡³': 304,\n",
       " 'ğŸ°': 302,\n",
       " 'âœŒğŸ¼': 299,\n",
       " 'ğŸº': 297,\n",
       " 'ğŸ¾': 296,\n",
       " '4ï¸âƒ£': 295,\n",
       " '5âƒ£': 294,\n",
       " 'ğŸ³ï¸\\u200dğŸŒˆ': 294,\n",
       " 'ğŸ˜§': 293,\n",
       " 'ğŸ¦': 293,\n",
       " 'âœğŸ½': 290,\n",
       " 'ğŸ’µ': 290,\n",
       " 'ğŸ§': 288,\n",
       " 'ğŸƒ': 287,\n",
       " 'â˜•': 286,\n",
       " 'ğŸ™ğŸ¿': 285,\n",
       " 'ğŸ‘ğŸ½': 284,\n",
       " 'â±': 283,\n",
       " 'â¬…ï¸': 283,\n",
       " 'ğŸ”™': 282,\n",
       " 'ğŸ•': 281,\n",
       " 'ğŸ˜Ÿ': 280,\n",
       " 'ğŸŠ': 279,\n",
       " 'ğŸ˜¿': 278,\n",
       " 'ğŸ¤¦\\u200dâ™€ï¸': 277,\n",
       " 'ğŸ™‹': 275,\n",
       " 'â†—': 273,\n",
       " 'ğŸ›‘': 272,\n",
       " 'ğŸ‡±ğŸ‡·': 272,\n",
       " 'ğŸ‹': 271,\n",
       " 'ğŸ’ğŸ½\\u200dâ™€ï¸': 267,\n",
       " 'â¬†ï¸': 266,\n",
       " 'âœŒğŸ½': 263,\n",
       " 'ğŸŸ': 263,\n",
       " 'ğŸŒµ': 262,\n",
       " 'ğŸ¹': 258,\n",
       " 'ğŸ—“ï¸': 258,\n",
       " 'ğŸ”ƒ': 258,\n",
       " 'âœ³ï¸': 256,\n",
       " 'â„': 255,\n",
       " 'ğŸ•’': 254,\n",
       " 'ğŸ¤’': 252,\n",
       " 'âœŠğŸ½': 252,\n",
       " 'ğŸ“½': 252,\n",
       " 'ğŸ¿': 251,\n",
       " 'ğŸ¸': 250,\n",
       " 'âš”ï¸': 250,\n",
       " 'ğŸ¤˜ğŸ¼': 249,\n",
       " 'ğŸ—£ï¸': 249,\n",
       " 'ğŸ¹': 249,\n",
       " 'ğŸ›«': 248,\n",
       " 'ğŸ’¢': 247,\n",
       " 'ğŸ‘': 247,\n",
       " 'ğŸ‘': 246,\n",
       " 'ğŸ­': 246,\n",
       " 'ğŸ‡¹ğŸ‡­': 246,\n",
       " 'âœï¸': 242,\n",
       " 'ğŸ”«': 242,\n",
       " 'ğŸ˜¦': 240,\n",
       " 'ğŸ‘ŠğŸ¼': 235,\n",
       " 'ğŸŸ': 235,\n",
       " 'ğŸ·': 234,\n",
       " 'ğŸ—½': 234,\n",
       " 'ğŸŒ': 233,\n",
       " 'ğŸ‰': 232,\n",
       " 'ğŸŒ³': 231,\n",
       " 'ğŸ¤˜ğŸ»': 230,\n",
       " 'ğŸ¨': 230,\n",
       " 'ğŸ¢': 230,\n",
       " 'ğŸŒ…': 229,\n",
       " 'ğŸ“‹': 229,\n",
       " 'âœŒğŸ¾': 224,\n",
       " 'âœï¸': 224,\n",
       " 'ğŸ‘¼': 224,\n",
       " 'ğŸš§': 224,\n",
       " 'ğŸ“€': 224,\n",
       " 'ğŸ¤˜ğŸ½': 221,\n",
       " 'â£': 220,\n",
       " 'â™ ': 220,\n",
       " 'ğŸ†“': 216,\n",
       " 'ğŸ‘º': 215,\n",
       " 'ğŸ–•': 215,\n",
       " 'ğŸ‘ŠğŸ¾': 215,\n",
       " 'â—': 214,\n",
       " 'â˜¹': 213,\n",
       " 'ğŸ‘¹': 213,\n",
       " 'ğŸŒ²': 212,\n",
       " 'ğŸ©': 212,\n",
       " 'â“': 212,\n",
       " 'ğŸ†˜': 211,\n",
       " 'ğŸ‡°ğŸ‡ª': 211,\n",
       " 'ğŸ‡µğŸ‡°': 211,\n",
       " 'ğŸ‡¹ğŸ‡·': 210,\n",
       " 'ğŸ¤™ğŸ¼': 209,\n",
       " 'ğŸ¼': 209,\n",
       " 'â†ªï¸': 209,\n",
       " 'â„¢': 207,\n",
       " 'ğŸ²': 205,\n",
       " 'ğŸ¥ˆ': 205,\n",
       " 'ğŸ”': 205,\n",
       " 'âšœï¸': 205,\n",
       " 'â˜„ï¸': 203,\n",
       " 'ğŸŒ': 202,\n",
       " 'ğŸ¬': 201,\n",
       " 'ğŸš—': 201,\n",
       " 'ğŸ“¦': 201,\n",
       " 'ğŸ‡µğŸ‡ª': 201,\n",
       " 'ğŸ¤™ğŸ½': 200,\n",
       " 'ğŸ‘‡ğŸ½': 200,\n",
       " 'ğŸ‡²ğŸ‡¾': 200,\n",
       " 'ğŸ‘‹ğŸ¼': 199,\n",
       " 'ğŸ¦‰': 199,\n",
       " 'ğŸ©': 199,\n",
       " 'ğŸ™': 197,\n",
       " 'ğŸ™€': 196,\n",
       " 'ğŸ‘„': 196,\n",
       " 'â™ ï¸': 196,\n",
       " 'ğŸ“': 196,\n",
       " 'ğŸ’ƒğŸ»': 195,\n",
       " 'ğŸ¦Š': 194,\n",
       " '\\U0001f995': 194,\n",
       " '\\U0001f9e2': 193,\n",
       " '5ï¸âƒ£': 193,\n",
       " 'ğŸ‰': 191,\n",
       " 'ğŸ‘£': 189,\n",
       " 'ğŸ’…': 188,\n",
       " 'ğŸ‘¾': 187,\n",
       " 'ğŸ˜¸': 187,\n",
       " 'ğŸ¤™ğŸ»': 187,\n",
       " 'ğŸ‡·ğŸ‡º': 186,\n",
       " 'ğŸ’‰': 185,\n",
       " 'ğŸ”·': 185,\n",
       " 'ğŸ’Š': 183,\n",
       " 'â—€ï¸': 183,\n",
       " 'ğŸ”': 182,\n",
       " 'ğŸŒ ': 182,\n",
       " 'ğŸ˜¼': 181,\n",
       " 'ğŸ’·': 181,\n",
       " 'ğŸ‘•': 180,\n",
       " 'ğŸ¤ğŸ»': 179,\n",
       " 'ğŸ‘ŠğŸ½': 178,\n",
       " 'ğŸ': 178,\n",
       " 'ğŸ‡': 178,\n",
       " 'ğŸ¥š': 177,\n",
       " 'ğŸ‘¸': 176,\n",
       " 'ğŸ¤ğŸ¼': 175,\n",
       " 'ğŸ”': 175,\n",
       " 'ğŸ—¿': 175,\n",
       " 'ğŸ': 173,\n",
       " 'ğŸª': 173,\n",
       " 'âœï¸': 173,\n",
       " 'â†˜': 170,\n",
       " 'â˜®ï¸': 169,\n",
       " 'ğŸ‘«': 167,\n",
       " 'ğŸ‘¤': 167,\n",
       " 'ğŸš²': 167,\n",
       " 'ğŸ¤¥': 166,\n",
       " 'ğŸŒ': 166,\n",
       " 'ğŸ…': 166,\n",
       " 'â•': 166,\n",
       " 'ğŸ‘¿': 165,\n",
       " 'ğŸ˜º': 164,\n",
       " 'ğŸ‡µğŸ‡¹': 164,\n",
       " 'ğŸ’ğŸ¼\\u200dâ™€ï¸': 163,\n",
       " 'â™¦ï¸': 163,\n",
       " 'ğŸ‘Ÿ': 163,\n",
       " 'ğŸ’ƒğŸ½': 161,\n",
       " 'ğŸ¤·ğŸ¿\\u200dâ™‚ï¸': 160,\n",
       " 'ğŸŒ¬': 160,\n",
       " 'ğŸ“¼': 160,\n",
       " 'âª': 160,\n",
       " 'ğŸš‚': 159,\n",
       " 'ğŸ¦‡': 157,\n",
       " 'â¤µ': 157,\n",
       " 'â„¹ï¸': 157,\n",
       " 'ğŸ™ŒğŸ¿': 155,\n",
       " 'ğŸ¤·': 155,\n",
       " 'â¬…': 155,\n",
       " 'ğŸ‡µğŸ‡¸': 155,\n",
       " 'ğŸ²': 153,\n",
       " 'ğŸ’¶': 153,\n",
       " 'ğŸ‡¬ğŸ‡­': 153,\n",
       " 'ğŸ¤™ğŸ¾': 152,\n",
       " 'ğŸœ': 152,\n",
       " 'ğŸ˜½': 151,\n",
       " 'ğŸ¤˜ğŸ¾': 149,\n",
       " 'ğŸ¦': 149,\n",
       " 'ğŸ¥': 149,\n",
       " 'ğŸ¼': 148,\n",
       " 'ğŸ”ª': 147,\n",
       " 'ğŸ‡®ğŸ‡ª': 147,\n",
       " 'ğŸ‘‡ğŸ¾': 146,\n",
       " 'ğŸ¸': 146,\n",
       " 'ğŸŒ§': 146,\n",
       " 'ğŸ‡§ğŸ‡ª': 146,\n",
       " 'ğŸŒ®': 145,\n",
       " 'ğŸ–¨': 145,\n",
       " '6ï¸âƒ£': 145,\n",
       " 'â–«ï¸': 145,\n",
       " 'ğŸ„': 144,\n",
       " 'ğŸˆ': 143,\n",
       " 'ğŸˆ': 143,\n",
       " 'ğŸ‡¨ğŸ‡±': 143,\n",
       " 'ğŸ‡³ğŸ‡´': 143,\n",
       " 'ğŸ': 142,\n",
       " 'ğŸ™': 142,\n",
       " '\\U0001f996': 141,\n",
       " 'ğŸ—³ï¸': 141,\n",
       " 'ğŸš©': 141,\n",
       " '\\U0001f91fğŸ½': 140,\n",
       " 'ğŸ˜': 140,\n",
       " 'ğŸ•·': 140,\n",
       " 'ğŸŒ¶': 140,\n",
       " 'ğŸšŒ': 140,\n",
       " 'ğŸŒƒ': 138,\n",
       " 'ğŸ­': 138,\n",
       " 'ğŸ¥‘': 137,\n",
       " 'ğŸ¦ˆ': 136,\n",
       " '\\U0001f9e0': 135,\n",
       " 'ğŸ¤¦ğŸ¼\\u200dâ™‚ï¸': 134,\n",
       " 'ğŸ’': 134,\n",
       " 'ğŸ”': 134,\n",
       " 'âœŠğŸ¼': 133,\n",
       " 'â†©': 133,\n",
       " 'ğŸ™…ğŸ¾\\u200dâ™‚ï¸': 132,\n",
       " 'ğŸŸ': 132,\n",
       " 'ğŸ›': 132,\n",
       " 'ğŸ”°': 132,\n",
       " 'ğŸœ': 131,\n",
       " 'ğŸ§€': 131,\n",
       " 'ğŸ‘“': 130,\n",
       " 'âš«': 130,\n",
       " 'ğŸ—¨': 129,\n",
       " 'ğŸ‘‰ğŸ¾': 129,\n",
       " 'ğŸ‚': 129,\n",
       " 'ğŸ¥': 129,\n",
       " 'ğŸ•µğŸ¼\\u200dâ™‚': 128,\n",
       " 'ğŸ•': 128,\n",
       " 'ğŸ‘¢': 128,\n",
       " 'ğŸ…°ï¸': 128,\n",
       " 'â˜”': 127,\n",
       " 'ğŸ': 127,\n",
       " 'âœ–ï¸': 127,\n",
       " 'ğŸ‘—': 126,\n",
       " 'âœ': 126,\n",
       " 'â˜': 125,\n",
       " 'ğŸ‘ğŸ¾': 125,\n",
       " 'ğŸ–': 125,\n",
       " 'ğŸ’‘': 124,\n",
       " 'â˜„': 124,\n",
       " 'ğŸ‘‰ğŸ½': 122,\n",
       " 'ğŸ™‡': 122,\n",
       " 'ğŸ†™': 122,\n",
       " 'ğŸ‘¥': 121,\n",
       " 'ğŸ•˜': 121,\n",
       " 'â˜ï¸': 121,\n",
       " 'ğŸ†”': 121,\n",
       " 'ğŸ¦': 120,\n",
       " 'ğŸ¬': 120,\n",
       " 'ğŸ‡': 120,\n",
       " 'ğŸ”Œ': 120,\n",
       " 'â˜ğŸ»': 119,\n",
       " 'ğŸŸ': 119,\n",
       " 'ğŸ¥‰': 119,\n",
       " 'ğŸ’\\u200dâ™€ï¸': 118,\n",
       " 'ğŸ´': 118,\n",
       " 'ğŸ’ˆ': 118,\n",
       " 'ğŸ™ï¸': 118,\n",
       " 'ğŸ¤¦': 117,\n",
       " 'âš¾': 117,\n",
       " 'ğŸ’': 117,\n",
       " 'ğŸ‘¶ğŸ»': 116,\n",
       " 'ğŸ™†': 116,\n",
       " 'ğŸŒª': 116,\n",
       " 'ğŸ‡¸ğŸ‡¾': 116,\n",
       " 'ğŸ™': 115,\n",
       " 'â™¦': 115,\n",
       " 'ğŸ¹': 115,\n",
       " 'ğŸ‡¸ğŸ‡ª': 115,\n",
       " 'â›”': 114,\n",
       " 'â˜ğŸ¾': 113,\n",
       " 'ğŸ›Œ': 113,\n",
       " 'âœ‚ï¸': 113,\n",
       " 'â†—ï¸': 113,\n",
       " 'ğŸ”º': 113,\n",
       " 'âœŠğŸ»': 112,\n",
       " 'ğŸ‘§': 112,\n",
       " 'ğŸ™‹ğŸ½\\u200dâ™€ï¸': 112,\n",
       " 'ğŸ–': 111,\n",
       " 'ğŸ„ğŸ»\\u200dâ™€ï¸': 111,\n",
       " '\\U0001f6f8': 111,\n",
       " 'âšª': 111,\n",
       " 'ğŸ‡³ğŸ‡±': 111,\n",
       " 'ğŸ³': 110,\n",
       " '\\U0001f91f': 109,\n",
       " 'ğŸ¤³': 109,\n",
       " 'ğŸ†': 109,\n",
       " 'âœ’': 109,\n",
       " 'â­•': 109,\n",
       " 'ğŸ†—': 109,\n",
       " 'ğŸ‘‹ğŸ½': 108,\n",
       " 'ğŸ‘ğŸ½': 108,\n",
       " '\\U0001f964': 108,\n",
       " 'ğŸ’ ': 108,\n",
       " 'ğŸŒ': 107,\n",
       " 'ğŸ¹': 107,\n",
       " 'ğŸ’…ğŸ½': 106,\n",
       " 'ğŸ’ğŸ¾\\u200dâ™€ï¸': 106,\n",
       " 'ğŸ': 106,\n",
       " 'ğŸ‰': 106,\n",
       " 'ğŸ’ƒğŸ¼': 105,\n",
       " 'ğŸŒ': 105,\n",
       " 'ğŸ¥ƒ': 105,\n",
       " 'ğŸ“©': 105,\n",
       " 'ğŸš¬': 105,\n",
       " 'ğŸ¤¦ğŸ¿\\u200dâ™‚ï¸': 104,\n",
       " 'ğŸ': 104,\n",
       " 'ğŸ’¼': 104,\n",
       " 'ğŸ‡': 103,\n",
       " 'ğŸµ': 103,\n",
       " 'ğŸ¥‹': 103,\n",
       " 'ğŸ”‚': 103,\n",
       " 'â': 103,\n",
       " 'ğŸ–•ğŸ½': 102,\n",
       " 'ğŸ”¨': 102,\n",
       " 'ğŸ“¡': 102,\n",
       " 'ğŸ‡®ğŸ‡±': 102,\n",
       " 'ğŸ´\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f': 102,\n",
       " 'ğŸ–•ğŸ¾': 101,\n",
       " 'ğŸ‘ï¸': 101,\n",
       " 'âš–ï¸': 101,\n",
       " 'âœ´': 101,\n",
       " 'ğŸ‡ªğŸ‡º': 101,\n",
       " 'ğŸšš': 100,\n",
       " 'ğŸ–‡': 100,\n",
       " '7ï¸âƒ£': 100,\n",
       " '\\U0001f91fğŸ¾': 99,\n",
       " 'ğŸ°': 99,\n",
       " 'ğŸ“‰': 99,\n",
       " 'ğŸ”Ÿ': 99,\n",
       " 'ğŸ‡¨ğŸ‡´': 99,\n",
       " 'ğŸ‡³ğŸ‡¿': 98,\n",
       " 'â˜ğŸ½': 97,\n",
       " 'ğŸ’…ğŸ¼': 97,\n",
       " 'ğŸ’…ğŸ¾': 97,\n",
       " 'ğŸƒ\\u200dâ™‚ï¸': 97,\n",
       " 'ğŸ€': 97,\n",
       " 'ğŸ›': 97,\n",
       " 'ğŸ¥”': 97,\n",
       " 'ğŸŒ¤': 97,\n",
       " 'ğŸ“¨': 97,\n",
       " 'ğŸŒ¾': 96,\n",
       " 'ğŸ': 96,\n",
       " 'ğŸ‘¸ğŸ»': 95,\n",
       " 'ğŸŠ': 95,\n",
       " 'ğŸ¦': 95,\n",
       " 'ğŸ••': 95,\n",
       " 'ğŸ': 95,\n",
       " 'ğŸ‡¬ğŸ‡·': 95,\n",
       " 'â‰ï¸': 94,\n",
       " 'ğŸ‘¼ğŸ½': 93,\n",
       " 'â˜˜': 93,\n",
       " 'ğŸ¾': 92,\n",
       " 'ğŸš¿': 92,\n",
       " 'â€¼': 92,\n",
       " 'ğŸš”': 91,\n",
       " 'ğŸŸï¸': 90,\n",
       " 'ğŸ„': 90,\n",
       " 'ğŸ”»': 90,\n",
       " 'ğŸ´\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f': 90,\n",
       " 'ğŸ¤': 89,\n",
       " 'ğŸ±': 89,\n",
       " 'ğŸ™†ğŸ¼\\u200dâ™‚ï¸': 88,\n",
       " 'ğŸ³': 88,\n",
       " 'ğŸ—': 88,\n",
       " 'ğŸš˜': 88,\n",
       " 'ğŸŸï¸': 88,\n",
       " 'ğŸ–¥': 88,\n",
       " 'ğŸ’…ğŸ¿': 87,\n",
       " 'â†©ï¸': 87,\n",
       " 'Â®': 87,\n",
       " 'ğŸ‡¯ğŸ‡²': 87,\n",
       " '\\U0001f91fğŸ¼': 86,\n",
       " 'ğŸ ': 84,\n",
       " 'ğŸ™‰': 83,\n",
       " 'ğŸšª': 83,\n",
       " 'â˜ ': 82,\n",
       " 'ğŸ™…ğŸ½\\u200dâ™€ï¸': 82,\n",
       " 'ğŸ™‹\\u200dâ™€ï¸': 82,\n",
       " 'ğŸ•ºğŸ½': 82,\n",
       " 'ğŸ': 82,\n",
       " 'ğŸ‘°': 81,\n",
       " 'ğŸ•ºğŸ»': 81,\n",
       " 'ğŸ¦†': 81,\n",
       " 'ğŸ¨': 81,\n",
       " 'ğŸ¡': 81,\n",
       " 'ğŸ“‚': 81,\n",
       " 'ğŸ‘‡ğŸ¿': 80,\n",
       " 'ğŸ‹': 80,\n",
       " 'ğŸ¥“': 80,\n",
       " 'ğŸ°': 80,\n",
       " 'ğŸ’³': 80,\n",
       " 'â›“': 80,\n",
       " 'â™»': 80,\n",
       " 'ğŸ‘‹ğŸ¾': 79,\n",
       " 'ğŸ–•ğŸ»': 79,\n",
       " 'ğŸ‘‚ğŸ¾': 79,\n",
       " 'ğŸ‘¯\\u200dâ™€ï¸': 79,\n",
       " 'ğŸš´': 79,\n",
       " 'ğŸ': 79,\n",
       " 'ğŸš¦': 79,\n",
       " 'ğŸ‘”': 79,\n",
       " 'âŒ¨ï¸': 79,\n",
       " 'ã€½ï¸': 79,\n",
       " 'ğŸ‡µğŸ‡±': 79,\n",
       " 'ğŸš¶': 78,\n",
       " 'ğŸ„': 78,\n",
       " 'ğŸŒ‹': 78,\n",
       " 'ğŸŒ„': 78,\n",
       " 'â†˜ï¸': 78,\n",
       " '9ï¸âƒ£': 78,\n",
       " 'ğŸ‡ºğŸ‡¬': 78,\n",
       " 'ğŸ‘©': 77,\n",
       " 'ğŸ‘¸ğŸ¼': 77,\n",
       " 'ğŸ‘¬': 77,\n",
       " 'ğŸ': 77,\n",
       " 'ğŸƒ': 77,\n",
       " 'ğŸ’ƒğŸ¾': 76,\n",
       " 'ğŸ½': 76,\n",
       " 'ğŸ¦ƒ': 76,\n",
       " 'ğŸ¥•': 76,\n",
       " 'ğŸ–': 76,\n",
       " 'ğŸ”¶': 76,\n",
       " 'ğŸ”': 75,\n",
       " 'ğŸŒ­': 75,\n",
       " 'â›ª': 75,\n",
       " 'ğŸ‡¿ğŸ‡¼': 75,\n",
       " 'â˜ğŸ¼': 74,\n",
       " 'ğŸ—º': 74,\n",
       " 'â±ï¸': 74,\n",
       " 'ğŸ•–': 74,\n",
       " 'ğŸ’': 74,\n",
       " 'ğŸ˜¾': 73,\n",
       " 'ğŸ¤´': 73,\n",
       " 'ğŸ…': 73,\n",
       " 'ğŸ¥—': 73,\n",
       " 'ğŸ½': 73,\n",
       " 'ğŸ´': 73,\n",
       " 'ğŸŒªï¸': 73,\n",
       " 'ğŸ‘­': 72,\n",
       " 'ğŸ': 72,\n",
       " 'â™¨': 72,\n",
       " 'ğŸš': 72,\n",
       " 'â›±': 72,\n",
       " 'ğŸ›': 72,\n",
       " 'ğŸ”“': 71,\n",
       " 'ğŸ‘‚': 70,\n",
       " 'ğŸ‘¯': 70,\n",
       " 'âŒš': 70,\n",
       " 'ğŸ¥…': 70,\n",
       " 'ğŸ’´': 70,\n",
       " 'ğŸ‘†ğŸ¼': 69,\n",
       " 'ğŸ‘ğŸ½': 69,\n",
       " '\\U0001f9df\\u200dâ™‚ï¸': 69,\n",
       " 'ğŸ†': 69,\n",
       " 'ğŸ®': 69,\n",
       " 'ğŸª': 69,\n",
       " 'ğŸ•¶': 69,\n",
       " 'ğŸ”¼': 69,\n",
       " 'ğŸ“›': 69,\n",
       " 'ğŸ‘ğŸ¼': 68,\n",
       " 'ğŸ•¶ï¸': 68,\n",
       " 'âœ‚': 68,\n",
       " 'ğŸ‡¸ğŸ‡¬': 68,\n",
       " 'ğŸ–•ğŸ¼': 67,\n",
       " 'ğŸƒ': 67,\n",
       " 'ğŸ‘–': 67,\n",
       " 'âœŠğŸ¿': 66,\n",
       " 'ğŸ’ğŸ»': 66,\n",
       " 'ğŸ’ğŸ¼': 66,\n",
       " 'âš’': 66,\n",
       " 'â—»ï¸': 66,\n",
       " 'â—¾': 66,\n",
       " 'ğŸ‡¦ğŸ‡²': 66,\n",
       " 'ğŸï¸': 65,\n",
       " 'ğŸš¢': 65,\n",
       " 'â˜£': 65,\n",
       " 'â—€': 65,\n",
       " 'ğŸ´': 65,\n",
       " 'ğŸ’®': 64,\n",
       " 'ğŸ¥œ': 64,\n",
       " 'ğŸ£': 64,\n",
       " 'ğŸ¦‘': 64,\n",
       " 'ğŸ”¦': 64,\n",
       " '8ï¸âƒ£': 64,\n",
       " 'ğŸµ': 63,\n",
       " 'ğŸ¦Œ': 63,\n",
       " 'ğŸŒ¯': 63,\n",
       " 'ğŸ£': 63,\n",
       " '\\U0001f9e5': 63,\n",
       " 'âš°ï¸': 63,\n",
       " 'âœ‹ğŸ»': 62,\n",
       " '\\U0001f91fğŸ»': 62,\n",
       " 'ğŸ‘ğŸ»': 62,\n",
       " 'ğŸ‘ğŸ¾': 62,\n",
       " 'ğŸ’ğŸ»\\u200dâ™‚ï¸': 62,\n",
       " 'ğŸ¥': 62,\n",
       " 'ğŸ›¬': 62,\n",
       " 'â›ˆ': 62,\n",
       " 'â›±ï¸': 62,\n",
       " 'â¬†': 62,\n",
       " 'âš›ï¸': 62,\n",
       " 'ğŸ’²': 62,\n",
       " 'ğŸ´\\u200dâ˜ ï¸': 62,\n",
       " 'ğŸ‡¿ğŸ‡²': 62,\n",
       " 'ğŸ‘ŒğŸ¿': 61,\n",
       " 'ğŸ™…': 61,\n",
       " 'ğŸ‘¸ğŸ½': 61,\n",
       " 'ğŸ…': 61,\n",
       " 'ğŸ’½': 61,\n",
       " 'ğŸ›’': 61,\n",
       " 'ğŸ‡¸ğŸ‡³': 61,\n",
       " 'ğŸ™‹ğŸ¼\\u200dâ™€ï¸': 60,\n",
       " 'ğŸ“': 60,\n",
       " 'â›…': 60,\n",
       " 'ğŸ•¹ï¸': 60,\n",
       " 'ğŸ”ˆ': 60,\n",
       " 'ğŸ‡¨ğŸ‡­': 60,\n",
       " 'ğŸŠ': 59,\n",
       " 'ğŸ’': 59,\n",
       " 'ğŸ•¸': 59,\n",
       " 'ğŸŒ‡': 59,\n",
       " 'âœ‰': 59,\n",
       " 'â•': 59,\n",
       " 'âœ´ï¸': 59,\n",
       " 'ğŸ––': 58,\n",
       " 'ğŸ‘ğŸ¾': 58,\n",
       " 'ğŸ’ªğŸ¿': 58,\n",
       " 'ğŸ™‡ğŸ½\\u200dâ™€ï¸': 58,\n",
       " 'ğŸŒ½': 58,\n",
       " 'ğŸ”‹': 58,\n",
       " 'ğŸ—': 57,\n",
       " 'ğŸ›': 57,\n",
       " 'ğŸ›‹ï¸': 57,\n",
       " 'ğŸ…±ï¸': 57,\n",
       " 'ğŸ‡¦ğŸ‡ª': 57,\n",
       " 'ğŸ‡«ğŸ‡®': 57,\n",
       " 'ğŸ‡¾ğŸ‡ª': 57,\n",
       " 'ğŸ‘ğŸ»': 56,\n",
       " 'ğŸ‘¸ğŸ¾': 56,\n",
       " 'ğŸš™': 56,\n",
       " 'ğŸ¤š': 55,\n",
       " 'ğŸ‘©ğŸ»': 55,\n",
       " 'ğŸ™†ğŸ»\\u200dâ™€ï¸': 55,\n",
       " 'ğŸ™‹\\u200dâ™‚ï¸': 55,\n",
       " 'ğŸ™‡\\u200dâ™€ï¸': 55,\n",
       " 'ğŸ–': 55,\n",
       " 'ğŸ': 55,\n",
       " 'ğŸ¦€': 55,\n",
       " 'â‡ï¸': 55,\n",
       " 'ğŸ’…ğŸ»': 54,\n",
       " 'ğŸ’ğŸ¼\\u200dâ™‚ï¸': 54,\n",
       " 'ğŸ•Šï¸': 54,\n",
       " 'ğŸ¥˜': 54,\n",
       " 'â›³': 54,\n",
       " ...}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ğŸ‘', 0.5708750486373901),\n",
       " ('ğŸ˜‰', 0.5507802963256836),\n",
       " ('ğŸ˜', 0.5429814457893372),\n",
       " ('â­ï¸i', 0.5380228757858276),\n",
       " ('awesom', 0.5341282486915588),\n",
       " ('ğŸ˜…', 0.5143481492996216),\n",
       " ('ğŸ¤—', 0.5049486756324768),\n",
       " ('ğŸ˜', 0.503909707069397),\n",
       " ('ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚', 0.4923427402973175),\n",
       " ('ğŸ˜˜', 0.4906120002269745),\n",
       " ('wonder', 0.48665982484817505),\n",
       " ('goan', 0.4851222038269043),\n",
       " ('jeanett', 0.47811296582221985),\n",
       " ('skyrim', 0.4774525463581085),\n",
       " ('ğŸ™€ğŸ™€ğŸ™€', 0.47732964158058167),\n",
       " ('ğŸ˜Š', 0.47706007957458496),\n",
       " ('ğŸ‘ğŸ‘Š', 0.4713195264339447),\n",
       " ('carsss', 0.47071343660354614),\n",
       " ('ğŸ˜thank', 0.4696727693080902),\n",
       " ('ğŸ’ğŸŒºğŸ’•', 0.4684681296348572)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar('ğŸ˜€',topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_prodictor('happi', model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ğŸ˜€',\n",
       " 'ğŸ˜€',\n",
       " 'ğŸ˜ƒ',\n",
       " 'ğŸ˜ƒ',\n",
       " 'ğŸ˜„',\n",
       " 'ğŸ˜„',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ˜†',\n",
       " 'ğŸ˜†',\n",
       " 'ğŸ˜…',\n",
       " 'ğŸ˜…',\n",
       " 'ğŸ¤£',\n",
       " 'ğŸ¤£',\n",
       " 'ğŸ˜‚',\n",
       " 'ğŸ˜‚',\n",
       " 'ğŸ™‚',\n",
       " 'ğŸ™‚',\n",
       " 'ğŸ™ƒ',\n",
       " 'ğŸ™ƒ',\n",
       " 'ğŸ˜‰',\n",
       " 'ğŸ˜‰',\n",
       " 'ğŸ˜Š',\n",
       " 'ğŸ˜Š',\n",
       " 'ğŸ˜‡',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ˜˜',\n",
       " 'ğŸ˜˜',\n",
       " 'ğŸ˜—',\n",
       " 'â˜ºï¸',\n",
       " 'â˜ºï¸',\n",
       " 'ğŸ˜š',\n",
       " 'ğŸ˜š',\n",
       " 'ğŸ˜™',\n",
       " 'ğŸ˜‹',\n",
       " 'ğŸ˜‹',\n",
       " 'ğŸ˜›',\n",
       " 'ğŸ˜œ',\n",
       " 'ğŸ˜œ',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ¤‘',\n",
       " 'ğŸ¤‘',\n",
       " 'ğŸ¤—',\n",
       " 'ğŸ¤—',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ˜Œ',\n",
       " 'ğŸ˜Œ',\n",
       " 'ğŸ¤¤',\n",
       " 'ğŸ¤ ',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ¤“',\n",
       " 'ğŸ¤“',\n",
       " 'ğŸ˜®',\n",
       " 'ğŸ˜¤',\n",
       " 'ğŸ˜¤',\n",
       " 'ğŸ¤¡',\n",
       " 'ğŸ¤¡',\n",
       " 'ğŸ™‹',\n",
       " 'ğŸ™‹ğŸ»',\n",
       " [...]]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dict['happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_pipeline(sentense):\n",
    "    out = [word for word in sentense.lower().split(\" \") if word not in stop]\n",
    "    out = [snowball.stem(word) for word in out]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentense = \"under\"\n",
    "[word for word in sentense.lower().split(\" \") if word not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pipeline(sentense)model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸ˜€'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_prodictor('us', model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸšŒ'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_prodictor('nyc', model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sherlock_homes.txt', 'r') as file:\n",
    "    text = file.read().lower()\n",
    "print('text length', len(text))\n",
    "chars = sorted(list(set(text))) # getting all unique chars\n",
    "print('total chars: ', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = \"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
    "                             verbose=1, save_best_only=True,\n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)\n",
    "callbacks = [print_callback, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, batch_size=128, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, diversity):\n",
    "    # Get random starting text\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(500, 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
