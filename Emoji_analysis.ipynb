{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data\n",
    "--------------\n",
    "## first check the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18866900 data/emojitweets-01-04-2018.txt\n"
     ]
    }
   ],
   "source": [
    "# check how many lines\n",
    "! wc -l data/emojitweets-01-04-2018.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209430000 data/emojitweets-01-04-2018.txt\n"
     ]
    }
   ],
   "source": [
    "# check how many words\n",
    "! wc -w data/emojitweets-01-04-2018.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.100392751326398"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On average the sentense are have 11 words\n",
    "209430000/18866900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - test - validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15093520.0, 1886690.0, 3773380.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split on 80-10-10\n",
    "18866900 * 0.8, 18866900 * 0.1, 18866900 * 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -15093520 data/emojitweets-01-04-2018.txt >>emoji_train.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail: error writing 'standard output': Broken pipe\n"
     ]
    }
   ],
   "source": [
    "! (tail -3773380 data/emojitweets-01-04-2018.txt | head -1886690) >> emoji_val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -1886690 data/emojitweets-01-04-2018.txt >> emoji_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate small_sample\n",
    "! head -1509352 data/emoji_train.txt >> data/emoji_ss.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to generate word vectors using Word2Vec \n",
    "  \n",
    "# importing all necessary modules \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "  \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "  \n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import emoji\n",
    "import regex\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = open(\"emoji_1M.txt\", \"r\") \n",
    "sample = open(\"data/emoji_ss.txt\", \"r\") \n",
    "s = sample.read() \n",
    "  \n",
    "# Replaces escape character with space \n",
    "f = s.replace(\"\\n\", \" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all \n",
    "notes = [\",\", \".\", \"/'\", \"(\" ,\")\", \"'\", '/\"', \":\", \";\", \"/\", \"(\", \")\", \"“\", \"”\", \"-\", \"+\", \"#\", \"…\", \"!\"]\n",
    "for note in notes:\n",
    "    f = f.replace(note, \"\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FULLLLLLLLLLLLL data\n",
    "sample = open(\"data/emoji_train.txt\", \"r\") \n",
    "s = sample.read() \n",
    "  \n",
    "# Replaces escape character with space \n",
    "f = s.replace(\"\\n\", \" \") \n",
    "# replace all \n",
    "notes = [\",\", \".\", \"/'\", \"(\" ,\")\", \"'\", '/\"', \":\", \";\", \"/\", \"(\", \")\", \"“\", \"”\", \"-\", \"+\", \"#\", \"…\", \"!\"]\n",
    "for note in notes:\n",
    "    f = f.replace(note, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "data = [] \n",
    "# iterate through each sentence in the file \n",
    "for i in sent_tokenize(f): \n",
    "    temp = [] \n",
    "      \n",
    "    # tokenize the sentence into words \n",
    "    for j in word_tokenize(i): \n",
    "        temp.append(j.lower()) \n",
    "  \n",
    "    data.append(temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84618238"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to helper\n",
    "def split_count(text):\n",
    "\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X', text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "\n",
    "    return emoji_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run for stemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "# remove stop words and snowball stemmer\n",
    "out = [[word for word in words if word not in stop] for words in data]\n",
    "snowball = SnowballStemmer('english')\n",
    "docs_snowball = [[snowball.stem(word) for word in words] for words in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79777"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_snowball)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_snowball[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save emoji list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4358"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emoji_list = list(emoji_set)\n",
    "# with open(\"emoji_list.csv\", 'w', newline='') as myfile:\n",
    "#      w = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "#      w.writerow(emoji_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"emoji_list.csv\", 'r', newline='') as myfile:\n",
    "#      emoji_list = csv.reader(myfile, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CBOW model \n",
    "model1 = gensim.models.Word2Vec(data, \n",
    "                                min_count = 10,  \n",
    "                                size = 300, \n",
    "                                window = 16,\n",
    "                                workers= 8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save CBOW model\n",
    "# import pickle\n",
    "# with open('cbow_ss.pkl', 'wb') as f:\n",
    "#     pickle.dump(model1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load CBOW model\n",
    "import pickle\n",
    "with open('cbow.pkl', 'rb') as f2:\n",
    "    model1_1 = pickle.load(f2)\n",
    "# print(model1_1 == model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(\"data/emoji_val.2csv\",index_col=0)\n",
    "emoji_set = emoji_list = val_df[\"emoji\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to helper\n",
    "def emoji_prodictor(word, model):\n",
    "    sim = model.most_similar(word,topn=75)\n",
    "    for i in sim:\n",
    "        if i[0] in emoji_list:\n",
    "            return i[0]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['let', 'go', 'groceri', 'buy', 'appl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move to helper\n",
    "def word_pipeline(sentense):\n",
    "    out = [word for word in sentense.lower().split(\" \") if word not in stop]\n",
    "    out = [snowball.stem(word) for word in out]\n",
    "    return out\n",
    "    \n",
    "    \n",
    "s1 = \"let's go grocery and buy some apple\"\n",
    "word_pipeline(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤷‍♀️\n",
      "🤦🏾‍♀️\n",
      "🛒\n",
      "💸\n",
      "👐🏽\n"
     ]
    }
   ],
   "source": [
    "s1 = \"let's go grocery and buy some apple\"\n",
    "for w in word_pipeline(s1):\n",
    "    print(emoji_prodictor(w, model1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'👌🏼'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_prodictor(\"today\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create skip-gram model \n",
    "model2 = gensim.models.Word2Vec(data, \n",
    "                                min_count = 10,  \n",
    "                                size = 300, \n",
    "                                window = 16,\n",
    "                                sg = 1,\n",
    "                                workers=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save skip-gram model\n",
    "# import pickle\n",
    "# with open('sg_ss.pkl', 'wb') as f:\n",
    "#     pickle.dump(model2, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load skip-gram model\n",
    "import pickle\n",
    "with open('sg_ss.pkl', 'rb') as f2:\n",
    "    model2_2 = pickle.load(f2)\n",
    "print(model2_2 == model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😂\n",
      "😂\n",
      "😀\n",
      "buy\n",
      "🍎\n"
     ]
    }
   ],
   "source": [
    "s1 = \"let's go grocery and buy some apples\"\n",
    "for w in word_pipeline(s1):\n",
    "    print(emoji_prodictor(w, model2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('now🎮', 0.7090588808059692),\n",
       " ('puzzle', 0.6862722635269165),\n",
       " ('now~🎮', 0.6172725558280945),\n",
       " ('google', 0.5657158493995667),\n",
       " ('on💡', 0.5306732058525085),\n",
       " ('stylish', 0.5125507712364197),\n",
       " ('missions', 0.5065516233444214),\n",
       " ('all😆', 0.4989703595638275),\n",
       " ('🎰', 0.4774476885795593),\n",
       " ('nightmare⚡️', 0.4716939926147461),\n",
       " ('app', 0.46512648463249207),\n",
       " ('fame🌟', 0.4634802043437958),\n",
       " ('days‼️', 0.4631275534629822),\n",
       " ('go‼️', 0.4629686772823334),\n",
       " ('trek', 0.4612944722175598),\n",
       " ('🔥who', 0.45808354020118713),\n",
       " ('shining', 0.4320569932460785),\n",
       " ('ever~🌟', 0.42865443229675293),\n",
       " ('🙋', 0.42692843079566956),\n",
       " ('play', 0.4189406931400299)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(\"star\",topn=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ground-truth\n",
    "with open('val_dict2.pickle', 'rb') as handle:\n",
    "    val_dict = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define score function with stemmer and trim stop words\n",
    "# def word2vec_score(val_dict, model):\n",
    "#     total_words = 0\n",
    "#     total_predicts = 0\n",
    "#     correct = 0\n",
    "#     words = []\n",
    "#     word_vectors = model.wv\n",
    "#     for word in val_dict:\n",
    "# #         print(word)\n",
    "#         if word_pipeline(word):\n",
    "#             w = word_pipeline(word)[0]\n",
    "#             words.append(w)\n",
    "#             if w in word_vectors:\n",
    "#                 total_words += 1\n",
    "#                 if emoji_prodictor(w, model) in val_dict[word]:\n",
    "#                     correct += 1\n",
    "#                     total_predicts += 1\n",
    "#                 elif emoji_prodictor(w, model) in emoji_set:\n",
    "#                     total_predicts += 1\n",
    "#     return correct/total_words, correct/total_predicts, words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define score function \n",
    "def word2vec_score(val_dict, model):\n",
    "    total_words = 0\n",
    "    total_predicts = 0\n",
    "    correct = 0\n",
    "    words = []\n",
    "    word_vectors = model.wv\n",
    "    for word in val_dict:\n",
    "#         print(word)\n",
    "        if word:\n",
    "            w = word.lower()\n",
    "            words.append(w)\n",
    "            if w in word_vectors:\n",
    "                total_words += 1\n",
    "                if emoji_prodictor(w, model) in val_dict[word]:\n",
    "                    correct += 1\n",
    "                    total_predicts += 1\n",
    "                elif emoji_prodictor(w, model) in emoji_set:\n",
    "                    total_predicts += 1\n",
    "    return correct/total_words, correct/total_predicts, words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = word2vec_score(val_dict, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = word2vec_score(val_dict, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline for ss, 0.04464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16235446313065977, 0.21978984238178634),\n",
       " (0.2128072445019405, 0.2634107285828663))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "Weighted score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_weighted_score(val_dict, model,emoji_frequency):\n",
    "    total_words = 0\n",
    "    total_weighted = 0\n",
    "    correct_weighted = 0\n",
    "#     words = []\n",
    "    word_vectors = model.wv\n",
    "    for word in val_dict:\n",
    "        if word:\n",
    "            w = word.lower()\n",
    "#             words.append(w)\n",
    "            if w in word_vectors:\n",
    "                total_words += 1\n",
    "                prediction = emoji_prodictor(w, model)\n",
    "                if prediction in val_dict[word]:\n",
    "                    correct_weighted += emoji_frequency[prediction]\n",
    "                    total_weighted += emoji_frequency[prediction]\n",
    "                elif prediction in emoji_set:\n",
    "                    total_weighted += emoji_frequency[prediction]\n",
    "    return correct_weighted/total_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.267386829730014"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model1, emoji_frequency)    # CBOW good at predicting more frequent word (high weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06241611360445485"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model2, emoji_frequency)    # Skip-gram good at predicting less frequent word (low weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "more restriction on prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new predictor with higher requirement to predict\n",
    "def emoji_prodictor(word, model):\n",
    "    sim = model.most_similar(word,topn=40)\n",
    "    for i in sim:\n",
    "        if i[0] in emoji_list and i[1] >= 0.55:\n",
    "            return i[0]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = word2vec_score(val_dict, model1)\n",
    "score2 = word2vec_score(val_dict, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.08711885500933417, 0.5072463768115942),\n",
       " (0.06782825140012445, 0.5647668393782384))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16 and new notes / predictor sim>=0.55\n",
    "# We can see improvement on accuracy but a drop in coverage\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5681407491990289"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model1, emoji_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12596177586164578"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model2, emoji_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "Model tuning history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL TRAIN\n",
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16 and no stemmer\n",
    "\n",
    "# score1[:2] (0.2809917355371901, 0.4602888086642599)\n",
    "# score2[:2] (0.30413223140495865, 0.4302416212003118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.1630012936610608, 0.2202797202797203),\n",
       " (0.21798188874514876, 0.27897350993377484))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16 and no stemmer\n",
    "# Looks like stemmer does not help much\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.256142944437114"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16 and new notes\n",
    "word2vec_weighted_score(val_dict, model1, emoji_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09182329105692395"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model2, emoji_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16490354698195395, 0.19188993482983346),\n",
       " (0.22028624766645924, 0.2512420156139106))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16 and new notes\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16936488169364883, 0.19470293486041518),\n",
       " (0.22478206724782068, 0.2565742714996446))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16 and new notes\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16084788029925187, 0.19068736141906872),\n",
       " (0.21571072319201995, 0.25181950509461426))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 16\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.15149625935162095, 0.17711370262390672),\n",
       " (0.21571072319201995, 0.24162011173184358))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 20\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.1589775561097257, 0.19480519480519481),\n",
       " (0.18952618453865336, 0.22943396226415094))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 150, window = 10\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.17206982543640897, 0.21052631578947367),\n",
       " (0.2013715710723192, 0.2492283950617284))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 300, window = 10\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16521197007481297, 0.1990984222389181),\n",
       " (0.20199501246882792, 0.2577565632458234))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 500, window = 10\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16390532544378697, 0.22124600638977635),\n",
       " (0.17810650887573964, 0.2872137404580153))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 5,  size = 500, window = 8\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16209476309226933, 0.19667170953101362),\n",
       " (0.19887780548628428, 0.2570507655116841))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 500, window = 8\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.14526184538653367, 0.19082719082719082),\n",
       " (0.1502493765586035, 0.21929026387625114))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score for CBOW and skipgram for SS WITH min_count = 10,  size = 500, window = 3\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.14964788732394366, 0.18695014662756598),\n",
       " (0.15307262569832403, 0.23539518900343642))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # score for CBOW and skipgram for small sample with SnowballStemmer\n",
    "# score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['😀',\n",
       " '💙',\n",
       " '🙌🏻',\n",
       " '👩🏾\\u200d\\U0001f9b3',\n",
       " '💁🏿\\u200d♂',\n",
       " '\\U0001f9d1\\u200d🎓',\n",
       " '\\U0001f9d1🏼\\u200d🎤',\n",
       " '💂🏿\\u200d♀',\n",
       " '\\U0001f9d1🏻\\u200d🎄',\n",
       " '\\U0001f9dd🏾\\u200d♂',\n",
       " '👨🏻\\u200d\\U0001f9bc',\n",
       " '🏄\\u200d♂',\n",
       " '🚵🏿\\u200d♂',\n",
       " '\\U0001f9d1🏾\\u200d🤝\\u200d\\U0001f9d1🏿',\n",
       " '\\U0001f9a6',\n",
       " '🍾',\n",
       " '🕑',\n",
       " '👘',\n",
       " '🔓',\n",
       " '⏪',\n",
       " '🏳',\n",
       " '🇵🇾']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_list[::200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word frequency\n",
    "c = Counter(f.split(\" \"))\n",
    "# c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emoji_freq\n",
    "emoji_frequency = {}\n",
    "\n",
    "total = 0\n",
    "for emoji in emoji_list:\n",
    "    emoji_frequency[emoji] = c[emoji]\n",
    "    total += c[emoji]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_frequency2 = {}\n",
    "for key, value in emoji_frequency.items():\n",
    "    emoji_frequency2[key] = value/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_freq = {k: v for k, v in sorted(emoji_frequency.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04464584326015571"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "69149/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'😂': 69149,\n",
       " '🔥': 33328,\n",
       " '❤️': 27982,\n",
       " '😭': 25433,\n",
       " '😍': 22820,\n",
       " '👉': 17657,\n",
       " '💕': 12445,\n",
       " '😊': 12041,\n",
       " '✨': 11794,\n",
       " '🤔': 10607,\n",
       " '👀': 10602,\n",
       " '😩': 10214,\n",
       " '❤': 10076,\n",
       " '💜': 8118,\n",
       " '🙄': 7977,\n",
       " '✅': 7664,\n",
       " '🚨': 7606,\n",
       " '💯': 7535,\n",
       " '🔔': 7372,\n",
       " '💙': 7344,\n",
       " '🤣': 7226,\n",
       " '😘': 7138,\n",
       " '💀': 7133,\n",
       " '😎': 6958,\n",
       " '😉': 6916,\n",
       " '💎': 6611,\n",
       " '🙌': 6543,\n",
       " '🙏': 6248,\n",
       " '©': 5899,\n",
       " '🎉': 5817,\n",
       " '💖': 5794,\n",
       " '🏆': 5700,\n",
       " '👏': 5532,\n",
       " '♨️': 5469,\n",
       " '💥': 5386,\n",
       " '😁': 5300,\n",
       " '📹': 5130,\n",
       " '🙃': 4995,\n",
       " '🌸': 4923,\n",
       " '😢': 4904,\n",
       " '👍': 4892,\n",
       " '📷': 4632,\n",
       " '🇺🇸': 4576,\n",
       " '🙏🏻': 4513,\n",
       " '➡️': 4484,\n",
       " '💛': 4405,\n",
       " '😳': 4359,\n",
       " '😅': 4335,\n",
       " '🗣': 4264,\n",
       " '👈': 4138,\n",
       " '🤗': 4078,\n",
       " '🎶': 3946,\n",
       " '👑': 3906,\n",
       " '😔': 3883,\n",
       " '💋': 3846,\n",
       " '💚': 3809,\n",
       " '😏': 3805,\n",
       " '☺️': 3799,\n",
       " '💗': 3671,\n",
       " '📸': 3641,\n",
       " '⏬': 3547,\n",
       " '♥️': 3539,\n",
       " '💫': 3525,\n",
       " '🔗': 3486,\n",
       " '🤷🏽\\u200d♀️': 3421,\n",
       " '💔': 3340,\n",
       " '🖤': 3287,\n",
       " '👌': 3287,\n",
       " '😌': 3283,\n",
       " '💪': 3282,\n",
       " '🌟': 3207,\n",
       " '👇': 3186,\n",
       " '🎥': 3134,\n",
       " '🙂': 3065,\n",
       " '😒': 3046,\n",
       " '➡': 3039,\n",
       " '😱': 3012,\n",
       " '✔️': 2994,\n",
       " '💞': 2985,\n",
       " '‼️': 2970,\n",
       " '🔴': 2924,\n",
       " '😈': 2911,\n",
       " '🌹': 2831,\n",
       " '🤦🏽\\u200d♀️': 2708,\n",
       " '😀': 2706,\n",
       " '♥': 2692,\n",
       " '🔜': 2675,\n",
       " '⚠': 2653,\n",
       " '😜': 2625,\n",
       " '😆': 2619,\n",
       " '⚡': 2478,\n",
       " '☀️': 2472,\n",
       " '😋': 2409,\n",
       " '😄': 2404,\n",
       " '💓': 2403,\n",
       " '🌑': 2402,\n",
       " '✔': 2384,\n",
       " '🌒': 2361,\n",
       " '😤': 2345,\n",
       " '🌓': 2339,\n",
       " '🤧': 2314,\n",
       " '🐰': 2295,\n",
       " '\\U0001f92a': 2237,\n",
       " '🎁': 2169,\n",
       " '📺': 2163,\n",
       " '💘': 2154,\n",
       " '😞': 2146,\n",
       " '😬': 2140,\n",
       " '🌕': 2125,\n",
       " '❌': 2124,\n",
       " '😪': 2123,\n",
       " '🚀': 2115,\n",
       " '🌘': 2028,\n",
       " '🌖': 2026,\n",
       " '🌗': 2023,\n",
       " '🌔': 2020,\n",
       " '⏰': 1997,\n",
       " '🌍': 1985,\n",
       " '☹️': 1984,\n",
       " '😇': 1973,\n",
       " '🙏🏾': 1899,\n",
       " '😐': 1851,\n",
       " '😴': 1843,\n",
       " '💦': 1843,\n",
       " '🙏🏽': 1759,\n",
       " '🙈': 1735,\n",
       " '🐣': 1734,\n",
       " '🌞': 1725,\n",
       " '📣': 1709,\n",
       " '😫': 1708,\n",
       " '⚠️': 1707,\n",
       " '🤷🏽\\u200d♂️': 1700,\n",
       " '👅': 1696,\n",
       " '💰': 1684,\n",
       " '😕': 1680,\n",
       " '🏨': 1658,\n",
       " '👊': 1655,\n",
       " '🌎': 1635,\n",
       " '🤤': 1583,\n",
       " '🤷🏾\\u200d♂️': 1577,\n",
       " '🌻': 1565,\n",
       " '📎': 1551,\n",
       " '👏🏻': 1545,\n",
       " '⬇️': 1545,\n",
       " '😃': 1531,\n",
       " '🍀': 1485,\n",
       " '🗳': 1480,\n",
       " '🔹': 1474,\n",
       " '📢': 1412,\n",
       " '🙏🏼': 1404,\n",
       " '🤷🏾\\u200d♀️': 1392,\n",
       " '\\U0001f929': 1385,\n",
       " '😑': 1368,\n",
       " '©️': 1361,\n",
       " '🤷🏻\\u200d♀️': 1360,\n",
       " '😡': 1351,\n",
       " '▶️': 1337,\n",
       " '🙌🏻': 1330,\n",
       " '🎂': 1326,\n",
       " '🔒': 1325,\n",
       " '💄': 1310,\n",
       " '🌆': 1307,\n",
       " '🌊': 1286,\n",
       " '🤦🏾\\u200d♂️': 1282,\n",
       " '📍': 1281,\n",
       " '👏🏼': 1259,\n",
       " '🐶': 1253,\n",
       " '▶': 1251,\n",
       " '🎧': 1243,\n",
       " '🎵': 1236,\n",
       " '😛': 1233,\n",
       " '🐯': 1228,\n",
       " '🤦🏽\\u200d♂️': 1221,\n",
       " '🍑': 1190,\n",
       " '🙌🏼': 1189,\n",
       " '✈️': 1186,\n",
       " '👍🏻': 1157,\n",
       " '🐥': 1157,\n",
       " '⚽': 1149,\n",
       " '😝': 1130,\n",
       " '🙌🏽': 1106,\n",
       " '👋': 1105,\n",
       " '🤦🏾\\u200d♀️': 1092,\n",
       " '😮': 1089,\n",
       " '☺': 1087,\n",
       " '🔘': 1084,\n",
       " '\\U0001f9d0': 1083,\n",
       " '🍃': 1068,\n",
       " '👠': 1045,\n",
       " '😥': 1042,\n",
       " '😻': 1036,\n",
       " '🌚': 1030,\n",
       " '🤦🏻\\u200d♀️': 1025,\n",
       " '\\U0001f92d': 1003,\n",
       " '🇬🇧': 999,\n",
       " '🤦🏻\\u200d♂️': 980,\n",
       " '\\U0001f928': 978,\n",
       " '🤷🏻\\u200d♂️': 978,\n",
       " '🌈': 960,\n",
       " '🐐': 953,\n",
       " '💧': 948,\n",
       " '🎬': 943,\n",
       " '💍': 942,\n",
       " '😣': 940,\n",
       " '\\U0001f9e1': 935,\n",
       " '🔵': 934,\n",
       " '🌙': 930,\n",
       " '\\U0001f92b': 923,\n",
       " '🙌🏾': 919,\n",
       " '😓': 911,\n",
       " '📌': 908,\n",
       " '🌷': 898,\n",
       " '▪️': 898,\n",
       " '🤢': 897,\n",
       " '❄️': 895,\n",
       " '➖': 890,\n",
       " '🎈': 868,\n",
       " '🎯': 864,\n",
       " '💪🏽': 860,\n",
       " '🤷🏼\\u200d♀️': 855,\n",
       " '❣️': 851,\n",
       " '🕑': 849,\n",
       " '😚': 846,\n",
       " '🇨🇦': 844,\n",
       " '🇫🇷': 835,\n",
       " '🥀': 833,\n",
       " '💸': 828,\n",
       " '🦋': 824,\n",
       " '🌴': 824,\n",
       " '💐': 822,\n",
       " '🔞': 820,\n",
       " '💌': 819,\n",
       " '🥇': 814,\n",
       " '💻': 805,\n",
       " '🏀': 801,\n",
       " '⬇': 799,\n",
       " '🕙': 795,\n",
       " '📈': 789,\n",
       " '🤓': 785,\n",
       " '👏🏽': 783,\n",
       " '☑️': 777,\n",
       " '🎮': 775,\n",
       " '🌺': 759,\n",
       " '1⃣': 757,\n",
       " '🎊': 740,\n",
       " '✌️': 737,\n",
       " '💨': 731,\n",
       " '🔁': 723,\n",
       " '🤘': 715,\n",
       " '💝': 714,\n",
       " '🐝': 709,\n",
       " '🇧🇷': 698,\n",
       " '👌🏻': 696,\n",
       " '🔊': 694,\n",
       " '😲': 693,\n",
       " '🇮🇹': 685,\n",
       " '🌼': 680,\n",
       " '🍻': 678,\n",
       " '🇪🇸': 676,\n",
       " '🎤': 669,\n",
       " '💣': 668,\n",
       " '📲': 667,\n",
       " '🤝': 660,\n",
       " '🌿': 660,\n",
       " '🎨': 660,\n",
       " '2⃣': 645,\n",
       " '😹': 644,\n",
       " '1️⃣': 644,\n",
       " '🔱': 639,\n",
       " '💪🏾': 631,\n",
       " '😶': 628,\n",
       " '🍁': 620,\n",
       " '💩': 618,\n",
       " '🆚': 617,\n",
       " '📻': 610,\n",
       " '💭': 605,\n",
       " '⏳': 603,\n",
       " '👍🏼': 600,\n",
       " '2️⃣': 597,\n",
       " '⭐': 592,\n",
       " '📅': 589,\n",
       " '🤑': 588,\n",
       " '\\U0001f92f': 586,\n",
       " '✊': 583,\n",
       " '🐍': 583,\n",
       " '📊': 579,\n",
       " '🔸': 576,\n",
       " '💟': 575,\n",
       " '📝': 572,\n",
       " '🇩🇪': 572,\n",
       " '👌🏾': 570,\n",
       " '🙋🏻\\u200d♀️': 570,\n",
       " '🌏': 570,\n",
       " '🐱': 568,\n",
       " '🆒': 567,\n",
       " '🙁': 564,\n",
       " '💪🏻': 563,\n",
       " '🌱': 563,\n",
       " '🏴\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f': 562,\n",
       " '🐻': 561,\n",
       " '🐾': 561,\n",
       " '🇮🇳': 561,\n",
       " '📱': 560,\n",
       " '📚': 556,\n",
       " '3⃣': 554,\n",
       " '✈': 550,\n",
       " '🏁': 550,\n",
       " '🦄': 548,\n",
       " '✌': 546,\n",
       " '😖': 545,\n",
       " '💃': 543,\n",
       " '🔄': 540,\n",
       " '🦁': 539,\n",
       " '👏🏾': 532,\n",
       " '4⃣': 530,\n",
       " '💬': 529,\n",
       " '💤': 527,\n",
       " '🤷\\u200d♀️': 526,\n",
       " '👉🏻': 523,\n",
       " '💪🏼': 523,\n",
       " '☁': 523,\n",
       " '😰': 522,\n",
       " '🇰🇷': 522,\n",
       " '👌🏼': 517,\n",
       " '👏🏿': 515,\n",
       " '🇿🇦': 514,\n",
       " '👇🏻': 513,\n",
       " '🍒': 513,\n",
       " '\\U0001f92c': 512,\n",
       " '😯': 509,\n",
       " '🤷\\u200d♂️': 509,\n",
       " '🇯🇵': 507,\n",
       " '👻': 505,\n",
       " '🇦🇷': 501,\n",
       " '👋🏻': 500,\n",
       " '🤠': 491,\n",
       " '👌🏽': 488,\n",
       " '🇦🇫': 484,\n",
       " '😵': 477,\n",
       " '🙊': 475,\n",
       " '🎀': 474,\n",
       " '⏩': 474,\n",
       " '3️⃣': 472,\n",
       " '🇵🇭': 469,\n",
       " '🕰️': 467,\n",
       " '🤕': 466,\n",
       " '\\U0001f92e': 466,\n",
       " '🇲🇽': 460,\n",
       " '☘️': 455,\n",
       " '☁️': 455,\n",
       " '🤐': 449,\n",
       " '🎼': 446,\n",
       " '😷': 444,\n",
       " '🤖': 440,\n",
       " '🚫': 439,\n",
       " '🤦🏼\\u200d♀️': 435,\n",
       " '🌀': 434,\n",
       " '🥂': 433,\n",
       " '👇🏼': 432,\n",
       " '🤞🏽': 427,\n",
       " '🍓': 427,\n",
       " '🤦\\u200d♂️': 420,\n",
       " '📆': 420,\n",
       " '✊🏾': 415,\n",
       " '📰': 412,\n",
       " '🔽': 411,\n",
       " '🕊': 405,\n",
       " '🤡': 403,\n",
       " '🎸': 403,\n",
       " '🔮': 401,\n",
       " '🎓': 401,\n",
       " '🚮': 398,\n",
       " '🍯': 396,\n",
       " '☑': 396,\n",
       " '😠': 395,\n",
       " '✋': 395,\n",
       " '🗓': 391,\n",
       " '😨': 390,\n",
       " '♻️': 390,\n",
       " '👊🏻': 389,\n",
       " '📽️': 388,\n",
       " '☝️': 385,\n",
       " '🍕': 385,\n",
       " '🤞': 380,\n",
       " '🖥️': 377,\n",
       " '👆': 376,\n",
       " '🐺': 375,\n",
       " '🔛': 375,\n",
       " '🆕': 373,\n",
       " '☠️': 370,\n",
       " '🔑': 370,\n",
       " '💡': 369,\n",
       " '😙': 364,\n",
       " '🏠': 364,\n",
       " '🏡': 362,\n",
       " '🤞🏾': 359,\n",
       " '⤵️': 358,\n",
       " '🇮🇩': 358,\n",
       " '💁🏻\\u200d♀️': 356,\n",
       " '🐇': 355,\n",
       " '🇦🇺': 355,\n",
       " '↪': 354,\n",
       " '🍭': 348,\n",
       " '🍆': 345,\n",
       " '🕺': 344,\n",
       " '🦅': 344,\n",
       " '🇵🇷': 344,\n",
       " '🇳🇬': 343,\n",
       " '🇧🇭': 340,\n",
       " '🍷': 339,\n",
       " '▪': 339,\n",
       " '💁': 338,\n",
       " '✌🏻': 337,\n",
       " '👐': 337,\n",
       " '🍫': 335,\n",
       " '🏃\\u200d♀️': 330,\n",
       " '💿': 329,\n",
       " '📖': 326,\n",
       " '🇪🇬': 324,\n",
       " '🤙': 323,\n",
       " '🔆': 321,\n",
       " '👽': 320,\n",
       " '🏘': 315,\n",
       " '🥊': 314,\n",
       " '😗': 313,\n",
       " '🍎': 312,\n",
       " '👙': 312,\n",
       " '☀': 311,\n",
       " '🔝': 310,\n",
       " '🌌': 309,\n",
       " '🏈': 307,\n",
       " '🤷🏼\\u200d♂️': 306,\n",
       " '👶': 305,\n",
       " '👉🏼': 304,\n",
       " '🐑': 304,\n",
       " '🇨🇳': 304,\n",
       " '🍰': 302,\n",
       " '✌🏼': 299,\n",
       " '🍺': 297,\n",
       " '🍾': 296,\n",
       " '4️⃣': 295,\n",
       " '5⃣': 294,\n",
       " '🏳️\\u200d🌈': 294,\n",
       " '😧': 293,\n",
       " '🐦': 293,\n",
       " '✍🏽': 290,\n",
       " '💵': 290,\n",
       " '🐧': 288,\n",
       " '🏃': 287,\n",
       " '☕': 286,\n",
       " '🙏🏿': 285,\n",
       " '👍🏽': 284,\n",
       " '⏱': 283,\n",
       " '⬅️': 283,\n",
       " '🔙': 282,\n",
       " '🐕': 281,\n",
       " '😟': 280,\n",
       " '🍊': 279,\n",
       " '😿': 278,\n",
       " '🤦\\u200d♀️': 277,\n",
       " '🙋': 275,\n",
       " '↗': 273,\n",
       " '🛑': 272,\n",
       " '🇱🇷': 272,\n",
       " '🍋': 271,\n",
       " '💁🏽\\u200d♀️': 267,\n",
       " '⬆️': 266,\n",
       " '✌🏽': 263,\n",
       " '🎟': 263,\n",
       " '🌵': 262,\n",
       " '🍹': 258,\n",
       " '🗓️': 258,\n",
       " '🔃': 258,\n",
       " '✳️': 256,\n",
       " '❄': 255,\n",
       " '🕒': 254,\n",
       " '🤒': 252,\n",
       " '✊🏽': 252,\n",
       " '📽': 252,\n",
       " '🍿': 251,\n",
       " '🐸': 250,\n",
       " '⚔️': 250,\n",
       " '🤘🏼': 249,\n",
       " '🗣️': 249,\n",
       " '🐹': 249,\n",
       " '🛫': 248,\n",
       " '💢': 247,\n",
       " '👎': 247,\n",
       " '👁': 246,\n",
       " '🐭': 246,\n",
       " '🇹🇭': 246,\n",
       " '✏️': 242,\n",
       " '🔫': 242,\n",
       " '😦': 240,\n",
       " '👊🏼': 235,\n",
       " '🏟': 235,\n",
       " '🐷': 234,\n",
       " '🗽': 234,\n",
       " '🌐': 233,\n",
       " '🍉': 232,\n",
       " '🌳': 231,\n",
       " '🤘🏻': 230,\n",
       " '🐨': 230,\n",
       " '🐢': 230,\n",
       " '🌅': 229,\n",
       " '📋': 229,\n",
       " '✌🏾': 224,\n",
       " '✍️': 224,\n",
       " '👼': 224,\n",
       " '🚧': 224,\n",
       " '📀': 224,\n",
       " '🤘🏽': 221,\n",
       " '❣': 220,\n",
       " '♠': 220,\n",
       " '🆓': 216,\n",
       " '👺': 215,\n",
       " '🖕': 215,\n",
       " '👊🏾': 215,\n",
       " '❗': 214,\n",
       " '☹': 213,\n",
       " '👹': 213,\n",
       " '🌲': 212,\n",
       " '🎩': 212,\n",
       " '❓': 212,\n",
       " '🆘': 211,\n",
       " '🇰🇪': 211,\n",
       " '🇵🇰': 211,\n",
       " '🇹🇷': 210,\n",
       " '🤙🏼': 209,\n",
       " '🐼': 209,\n",
       " '↪️': 209,\n",
       " '™': 207,\n",
       " '🐲': 205,\n",
       " '🥈': 205,\n",
       " '🔐': 205,\n",
       " '⚜️': 205,\n",
       " '☄️': 203,\n",
       " '🍌': 202,\n",
       " '🐬': 201,\n",
       " '🚗': 201,\n",
       " '📦': 201,\n",
       " '🇵🇪': 201,\n",
       " '🤙🏽': 200,\n",
       " '👇🏽': 200,\n",
       " '🇲🇾': 200,\n",
       " '👋🏼': 199,\n",
       " '🦉': 199,\n",
       " '🍩': 199,\n",
       " '🏙': 197,\n",
       " '🙀': 196,\n",
       " '👄': 196,\n",
       " '♠️': 196,\n",
       " '📞': 196,\n",
       " '💃🏻': 195,\n",
       " '🦊': 194,\n",
       " '\\U0001f995': 194,\n",
       " '\\U0001f9e2': 193,\n",
       " '5️⃣': 193,\n",
       " '🐉': 191,\n",
       " '👣': 189,\n",
       " '💅': 188,\n",
       " '👾': 187,\n",
       " '😸': 187,\n",
       " '🤙🏻': 187,\n",
       " '🇷🇺': 186,\n",
       " '💉': 185,\n",
       " '🔷': 185,\n",
       " '💊': 183,\n",
       " '◀️': 183,\n",
       " '🍔': 182,\n",
       " '🌠': 182,\n",
       " '😼': 181,\n",
       " '💷': 181,\n",
       " '👕': 180,\n",
       " '🤞🏻': 179,\n",
       " '👊🏽': 178,\n",
       " '🐎': 178,\n",
       " '🍇': 178,\n",
       " '🥚': 177,\n",
       " '👸': 176,\n",
       " '🤞🏼': 175,\n",
       " '🔎': 175,\n",
       " '🗿': 175,\n",
       " '🍍': 173,\n",
       " '🍪': 173,\n",
       " '✝️': 173,\n",
       " '↘': 170,\n",
       " '☮️': 169,\n",
       " '👫': 167,\n",
       " '👤': 167,\n",
       " '🚲': 167,\n",
       " '🤥': 166,\n",
       " '🌝': 166,\n",
       " '🏅': 166,\n",
       " '➕': 166,\n",
       " '👿': 165,\n",
       " '😺': 164,\n",
       " '🇵🇹': 164,\n",
       " '💁🏼\\u200d♀️': 163,\n",
       " '♦️': 163,\n",
       " '👟': 163,\n",
       " '💃🏽': 161,\n",
       " '🤷🏿\\u200d♂️': 160,\n",
       " '🌬': 160,\n",
       " '📼': 160,\n",
       " '⏪': 160,\n",
       " '🚂': 159,\n",
       " '🦇': 157,\n",
       " '⤵': 157,\n",
       " 'ℹ️': 157,\n",
       " '🙌🏿': 155,\n",
       " '🤷': 155,\n",
       " '⬅': 155,\n",
       " '🇵🇸': 155,\n",
       " '🎲': 153,\n",
       " '💶': 153,\n",
       " '🇬🇭': 153,\n",
       " '🤙🏾': 152,\n",
       " '🍜': 152,\n",
       " '😽': 151,\n",
       " '🤘🏾': 149,\n",
       " '🍦': 149,\n",
       " '🥁': 149,\n",
       " '🍼': 148,\n",
       " '🔪': 147,\n",
       " '🇮🇪': 147,\n",
       " '👇🏾': 146,\n",
       " '🍸': 146,\n",
       " '🌧': 146,\n",
       " '🇧🇪': 146,\n",
       " '🌮': 145,\n",
       " '🖨': 145,\n",
       " '6️⃣': 145,\n",
       " '▫️': 145,\n",
       " '🍄': 144,\n",
       " '🐈': 143,\n",
       " '🍈': 143,\n",
       " '🇨🇱': 143,\n",
       " '🇳🇴': 143,\n",
       " '🏝': 142,\n",
       " '🎙': 142,\n",
       " '\\U0001f996': 141,\n",
       " '🗳️': 141,\n",
       " '🚩': 141,\n",
       " '\\U0001f91f🏽': 140,\n",
       " '🐘': 140,\n",
       " '🕷': 140,\n",
       " '🌶': 140,\n",
       " '🚌': 140,\n",
       " '🌃': 138,\n",
       " '🎭': 138,\n",
       " '🥑': 137,\n",
       " '🦈': 136,\n",
       " '\\U0001f9e0': 135,\n",
       " '🤦🏼\\u200d♂️': 134,\n",
       " '🐒': 134,\n",
       " '🔍': 134,\n",
       " '✊🏼': 133,\n",
       " '↩': 133,\n",
       " '🙅🏾\\u200d♂️': 132,\n",
       " '🐟': 132,\n",
       " '🛎': 132,\n",
       " '🔰': 132,\n",
       " '🐜': 131,\n",
       " '🧀': 131,\n",
       " '👓': 130,\n",
       " '⚫': 130,\n",
       " '🗨': 129,\n",
       " '👉🏾': 129,\n",
       " '🍂': 129,\n",
       " '🍥': 129,\n",
       " '🕵🏼\\u200d♂': 128,\n",
       " '🕐': 128,\n",
       " '👢': 128,\n",
       " '🅰️': 128,\n",
       " '☔': 127,\n",
       " '🏏': 127,\n",
       " '✖️': 127,\n",
       " '👗': 126,\n",
       " '✏': 126,\n",
       " '☝': 125,\n",
       " '👍🏾': 125,\n",
       " '🏖': 125,\n",
       " '💑': 124,\n",
       " '☄': 124,\n",
       " '👉🏽': 122,\n",
       " '🙇': 122,\n",
       " '🆙': 122,\n",
       " '👥': 121,\n",
       " '🕘': 121,\n",
       " '☎️': 121,\n",
       " '🆔': 121,\n",
       " '🦍': 120,\n",
       " '🍬': 120,\n",
       " '🎇': 120,\n",
       " '🔌': 120,\n",
       " '☝🏻': 119,\n",
       " '🍟': 119,\n",
       " '🥉': 119,\n",
       " '💁\\u200d♀️': 118,\n",
       " '🐴': 118,\n",
       " '💈': 118,\n",
       " '🎙️': 118,\n",
       " '🤦': 117,\n",
       " '⚾': 117,\n",
       " '🏒': 117,\n",
       " '👶🏻': 116,\n",
       " '🙆': 116,\n",
       " '🌪': 116,\n",
       " '🇸🇾': 116,\n",
       " '🐙': 115,\n",
       " '♦': 115,\n",
       " '🏹': 115,\n",
       " '🇸🇪': 115,\n",
       " '⛔': 114,\n",
       " '☝🏾': 113,\n",
       " '🛌': 113,\n",
       " '✂️': 113,\n",
       " '↗️': 113,\n",
       " '🔺': 113,\n",
       " '✊🏻': 112,\n",
       " '👧': 112,\n",
       " '🙋🏽\\u200d♀️': 112,\n",
       " '🖐': 111,\n",
       " '🏄🏻\\u200d♀️': 111,\n",
       " '\\U0001f6f8': 111,\n",
       " '⚪': 111,\n",
       " '🇳🇱': 111,\n",
       " '🍳': 110,\n",
       " '\\U0001f91f': 109,\n",
       " '🤳': 109,\n",
       " '🎆': 109,\n",
       " '✒': 109,\n",
       " '⭕': 109,\n",
       " '🆗': 109,\n",
       " '👋🏽': 108,\n",
       " '👐🏽': 108,\n",
       " '\\U0001f964': 108,\n",
       " '💠': 108,\n",
       " '🏌': 107,\n",
       " '🎹': 107,\n",
       " '💅🏽': 106,\n",
       " '💁🏾\\u200d♀️': 106,\n",
       " '🏎': 106,\n",
       " '🏉': 106,\n",
       " '💃🏼': 105,\n",
       " '🐌': 105,\n",
       " '🥃': 105,\n",
       " '📩': 105,\n",
       " '🚬': 105,\n",
       " '🤦🏿\\u200d♂️': 104,\n",
       " '🍐': 104,\n",
       " '💼': 104,\n",
       " '🏇': 103,\n",
       " '🍵': 103,\n",
       " '🥋': 103,\n",
       " '🔂': 103,\n",
       " '❎': 103,\n",
       " '🖕🏽': 102,\n",
       " '🔨': 102,\n",
       " '📡': 102,\n",
       " '🇮🇱': 102,\n",
       " '🏴\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f': 102,\n",
       " '🖕🏾': 101,\n",
       " '👁️': 101,\n",
       " '⚖️': 101,\n",
       " '✴': 101,\n",
       " '🇪🇺': 101,\n",
       " '🚚': 100,\n",
       " '🖇': 100,\n",
       " '7️⃣': 100,\n",
       " '\\U0001f91f🏾': 99,\n",
       " '🎰': 99,\n",
       " '📉': 99,\n",
       " '🔟': 99,\n",
       " '🇨🇴': 99,\n",
       " '🇳🇿': 98,\n",
       " '☝🏽': 97,\n",
       " '💅🏼': 97,\n",
       " '💅🏾': 97,\n",
       " '🏃\\u200d♂️': 97,\n",
       " '🐀': 97,\n",
       " '🐛': 97,\n",
       " '🥔': 97,\n",
       " '🌤': 97,\n",
       " '📨': 97,\n",
       " '🌾': 96,\n",
       " '🍏': 96,\n",
       " '👸🏻': 95,\n",
       " '🐊': 95,\n",
       " '🦎': 95,\n",
       " '🕕': 95,\n",
       " '🎞': 95,\n",
       " '🇬🇷': 95,\n",
       " '⁉️': 94,\n",
       " '👼🏽': 93,\n",
       " '☘': 93,\n",
       " '🎾': 92,\n",
       " '🚿': 92,\n",
       " '‼': 92,\n",
       " '🚔': 91,\n",
       " '🏟️': 90,\n",
       " '🎄': 90,\n",
       " '🔻': 90,\n",
       " '🏴\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f': 90,\n",
       " '🐤': 89,\n",
       " '🎱': 89,\n",
       " '🙆🏼\\u200d♂️': 88,\n",
       " '🐳': 88,\n",
       " '🍗': 88,\n",
       " '🚘': 88,\n",
       " '🎟️': 88,\n",
       " '🖥': 88,\n",
       " '💅🏿': 87,\n",
       " '↩️': 87,\n",
       " '®': 87,\n",
       " '🇯🇲': 87,\n",
       " '\\U0001f91f🏼': 86,\n",
       " '🐠': 84,\n",
       " '🙉': 83,\n",
       " '🚪': 83,\n",
       " '☠': 82,\n",
       " '🙅🏽\\u200d♀️': 82,\n",
       " '🙋\\u200d♀️': 82,\n",
       " '🕺🏽': 82,\n",
       " '🏐': 82,\n",
       " '👰': 81,\n",
       " '🕺🏻': 81,\n",
       " '🦆': 81,\n",
       " '🍨': 81,\n",
       " '🎡': 81,\n",
       " '📂': 81,\n",
       " '👇🏿': 80,\n",
       " '🐋': 80,\n",
       " '🥓': 80,\n",
       " '🏰': 80,\n",
       " '💳': 80,\n",
       " '⛓': 80,\n",
       " '♻': 80,\n",
       " '👋🏾': 79,\n",
       " '🖕🏻': 79,\n",
       " '👂🏾': 79,\n",
       " '👯\\u200d♀️': 79,\n",
       " '🚴': 79,\n",
       " '🍝': 79,\n",
       " '🚦': 79,\n",
       " '👔': 79,\n",
       " '⌨️': 79,\n",
       " '〽️': 79,\n",
       " '🇵🇱': 79,\n",
       " '🚶': 78,\n",
       " '🐄': 78,\n",
       " '🌋': 78,\n",
       " '🌄': 78,\n",
       " '↘️': 78,\n",
       " '9️⃣': 78,\n",
       " '🇺🇬': 78,\n",
       " '👩': 77,\n",
       " '👸🏼': 77,\n",
       " '👬': 77,\n",
       " '🍞': 77,\n",
       " '🎃': 77,\n",
       " '💃🏾': 76,\n",
       " '🐽': 76,\n",
       " '🦃': 76,\n",
       " '🥕': 76,\n",
       " '🎖': 76,\n",
       " '🔶': 76,\n",
       " '🐔': 75,\n",
       " '🌭': 75,\n",
       " '⛪': 75,\n",
       " '🇿🇼': 75,\n",
       " '☝🏼': 74,\n",
       " '🗺': 74,\n",
       " '⏱️': 74,\n",
       " '🕖': 74,\n",
       " '🎒': 74,\n",
       " '😾': 73,\n",
       " '🤴': 73,\n",
       " '🐅': 73,\n",
       " '🥗': 73,\n",
       " '🍽': 73,\n",
       " '🍴': 73,\n",
       " '🌪️': 73,\n",
       " '👭': 72,\n",
       " '🐞': 72,\n",
       " '♨': 72,\n",
       " '🚁': 72,\n",
       " '⛱': 72,\n",
       " '🛏': 72,\n",
       " '🔓': 71,\n",
       " '👂': 70,\n",
       " '👯': 70,\n",
       " '⌚': 70,\n",
       " '🥅': 70,\n",
       " '💴': 70,\n",
       " '👆🏼': 69,\n",
       " '👎🏽': 69,\n",
       " '\\U0001f9df\\u200d♂️': 69,\n",
       " '🐆': 69,\n",
       " '🐮': 69,\n",
       " '🎪': 69,\n",
       " '🕶': 69,\n",
       " '🔼': 69,\n",
       " '📛': 69,\n",
       " '👎🏼': 68,\n",
       " '🕶️': 68,\n",
       " '✂': 68,\n",
       " '🇸🇬': 68,\n",
       " '🖕🏼': 67,\n",
       " '🃏': 67,\n",
       " '👖': 67,\n",
       " '✊🏿': 66,\n",
       " '💁🏻': 66,\n",
       " '💁🏼': 66,\n",
       " '⚒': 66,\n",
       " '◻️': 66,\n",
       " '◾': 66,\n",
       " '🇦🇲': 66,\n",
       " '🏍️': 65,\n",
       " '🚢': 65,\n",
       " '☣': 65,\n",
       " '◀': 65,\n",
       " '🏴': 65,\n",
       " '💮': 64,\n",
       " '🥜': 64,\n",
       " '🍣': 64,\n",
       " '🦑': 64,\n",
       " '🔦': 64,\n",
       " '8️⃣': 64,\n",
       " '🐵': 63,\n",
       " '🦌': 63,\n",
       " '🌯': 63,\n",
       " '🎣': 63,\n",
       " '\\U0001f9e5': 63,\n",
       " '⚰️': 63,\n",
       " '✋🏻': 62,\n",
       " '\\U0001f91f🏻': 62,\n",
       " '👎🏻': 62,\n",
       " '👐🏾': 62,\n",
       " '💁🏻\\u200d♂️': 62,\n",
       " '🥝': 62,\n",
       " '🛬': 62,\n",
       " '⛈': 62,\n",
       " '⛱️': 62,\n",
       " '⬆': 62,\n",
       " '⚛️': 62,\n",
       " '💲': 62,\n",
       " '🏴\\u200d☠️': 62,\n",
       " '🇿🇲': 62,\n",
       " '👌🏿': 61,\n",
       " '🙅': 61,\n",
       " '👸🏽': 61,\n",
       " '🍅': 61,\n",
       " '💽': 61,\n",
       " '🛒': 61,\n",
       " '🇸🇳': 61,\n",
       " '🙋🏼\\u200d♀️': 60,\n",
       " '🐓': 60,\n",
       " '⛅': 60,\n",
       " '🕹️': 60,\n",
       " '🔈': 60,\n",
       " '🇨🇭': 60,\n",
       " '🏊': 59,\n",
       " '💏': 59,\n",
       " '🕸': 59,\n",
       " '🌇': 59,\n",
       " '✉': 59,\n",
       " '❕': 59,\n",
       " '✴️': 59,\n",
       " '🖖': 58,\n",
       " '👎🏾': 58,\n",
       " '💪🏿': 58,\n",
       " '🙇🏽\\u200d♀️': 58,\n",
       " '🌽': 58,\n",
       " '🔋': 58,\n",
       " '🎗': 57,\n",
       " '🛍': 57,\n",
       " '🛋️': 57,\n",
       " '🅱️': 57,\n",
       " '🇦🇪': 57,\n",
       " '🇫🇮': 57,\n",
       " '🇾🇪': 57,\n",
       " '👐🏻': 56,\n",
       " '👸🏾': 56,\n",
       " '🚙': 56,\n",
       " '🤚': 55,\n",
       " '👩🏻': 55,\n",
       " '🙆🏻\\u200d♀️': 55,\n",
       " '🙋\\u200d♂️': 55,\n",
       " '🙇\\u200d♀️': 55,\n",
       " '🐖': 55,\n",
       " '🐏': 55,\n",
       " '🦀': 55,\n",
       " '❇️': 55,\n",
       " '💅🏻': 54,\n",
       " '💁🏼\\u200d♂️': 54,\n",
       " '🕊️': 54,\n",
       " '🥘': 54,\n",
       " '⛳': 54,\n",
       " ...}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4168, 2446)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_count = 0\n",
    "count = 0\n",
    "for key, value in sort_freq.items():\n",
    "    count += 1\n",
    "    if value > 0:\n",
    "        non_zero_count += 1\n",
    "count, non_zero_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['😂',\n",
       " '🔥',\n",
       " '❤️',\n",
       " '😭',\n",
       " '😍',\n",
       " '👉',\n",
       " '💕',\n",
       " '😊',\n",
       " '✨',\n",
       " '🤔',\n",
       " '👀',\n",
       " '😩',\n",
       " '❤',\n",
       " '💜',\n",
       " '🙄',\n",
       " '✅',\n",
       " '🚨',\n",
       " '💯',\n",
       " '🔔',\n",
       " '💙',\n",
       " '🤣',\n",
       " '😘',\n",
       " '💀',\n",
       " '😎',\n",
       " '😉',\n",
       " '💎',\n",
       " '🙌',\n",
       " '🙏',\n",
       " '©',\n",
       " '🎉',\n",
       " '💖',\n",
       " '🏆',\n",
       " '👏',\n",
       " '♨️',\n",
       " '💥',\n",
       " '😁',\n",
       " '📹',\n",
       " '🙃',\n",
       " '🌸',\n",
       " '😢',\n",
       " '👍',\n",
       " '📷',\n",
       " '🇺🇸',\n",
       " '🙏🏻',\n",
       " '➡️',\n",
       " '💛',\n",
       " '😳',\n",
       " '😅',\n",
       " '🗣',\n",
       " '👈',\n",
       " '🤗',\n",
       " '🎶',\n",
       " '👑',\n",
       " '😔',\n",
       " '💋',\n",
       " '💚',\n",
       " '😏',\n",
       " '☺️',\n",
       " '💗',\n",
       " '📸',\n",
       " '⏬',\n",
       " '♥️',\n",
       " '💫',\n",
       " '🔗',\n",
       " '🤷🏽\\u200d♀️',\n",
       " '💔',\n",
       " '🖤',\n",
       " '👌',\n",
       " '😌',\n",
       " '💪',\n",
       " '🌟',\n",
       " '👇',\n",
       " '🎥',\n",
       " '🙂',\n",
       " '😒',\n",
       " '➡',\n",
       " '😱',\n",
       " '✔️',\n",
       " '💞',\n",
       " '‼️',\n",
       " '🔴',\n",
       " '😈',\n",
       " '🌹',\n",
       " '🤦🏽\\u200d♀️',\n",
       " '😀',\n",
       " '♥',\n",
       " '🔜',\n",
       " '⚠',\n",
       " '😜',\n",
       " '😆',\n",
       " '⚡',\n",
       " '☀️',\n",
       " '😋',\n",
       " '😄',\n",
       " '💓',\n",
       " '🌑',\n",
       " '✔',\n",
       " '🌒',\n",
       " '😤',\n",
       " '🌓',\n",
       " '🤧',\n",
       " '🐰',\n",
       " '\\U0001f92a',\n",
       " '🎁',\n",
       " '📺',\n",
       " '💘',\n",
       " '😞',\n",
       " '😬',\n",
       " '🌕',\n",
       " '❌',\n",
       " '😪',\n",
       " '🚀',\n",
       " '🌘',\n",
       " '🌖',\n",
       " '🌗',\n",
       " '🌔',\n",
       " '⏰',\n",
       " '🌍',\n",
       " '☹️',\n",
       " '😇',\n",
       " '🙏🏾',\n",
       " '😐',\n",
       " '😴',\n",
       " '💦',\n",
       " '🙏🏽',\n",
       " '🙈',\n",
       " '🐣',\n",
       " '🌞',\n",
       " '📣',\n",
       " '😫',\n",
       " '⚠️',\n",
       " '🤷🏽\\u200d♂️',\n",
       " '👅',\n",
       " '💰',\n",
       " '😕',\n",
       " '🏨',\n",
       " '👊',\n",
       " '🌎',\n",
       " '🤤',\n",
       " '🤷🏾\\u200d♂️',\n",
       " '🌻',\n",
       " '📎',\n",
       " '👏🏻',\n",
       " '⬇️',\n",
       " '😃',\n",
       " '🍀',\n",
       " '🗳',\n",
       " '🔹',\n",
       " '📢',\n",
       " '🙏🏼',\n",
       " '🤷🏾\\u200d♀️',\n",
       " '\\U0001f929',\n",
       " '😑',\n",
       " '©️',\n",
       " '🤷🏻\\u200d♀️',\n",
       " '😡',\n",
       " '▶️',\n",
       " '🙌🏻',\n",
       " '🎂',\n",
       " '🔒',\n",
       " '💄',\n",
       " '🌆',\n",
       " '🌊',\n",
       " '🤦🏾\\u200d♂️',\n",
       " '📍',\n",
       " '👏🏼',\n",
       " '🐶',\n",
       " '▶',\n",
       " '🎧',\n",
       " '🎵',\n",
       " '😛',\n",
       " '🐯',\n",
       " '🤦🏽\\u200d♂️',\n",
       " '🍑',\n",
       " '🙌🏼',\n",
       " '✈️',\n",
       " '👍🏻',\n",
       " '🐥',\n",
       " '⚽',\n",
       " '😝',\n",
       " '🙌🏽',\n",
       " '👋',\n",
       " '🤦🏾\\u200d♀️',\n",
       " '😮',\n",
       " '☺',\n",
       " '🔘',\n",
       " '\\U0001f9d0',\n",
       " '🍃',\n",
       " '👠',\n",
       " '😥',\n",
       " '😻',\n",
       " '🌚',\n",
       " '🤦🏻\\u200d♀️',\n",
       " '\\U0001f92d',\n",
       " '🇬🇧',\n",
       " '🤦🏻\\u200d♂️',\n",
       " '\\U0001f928',\n",
       " '🤷🏻\\u200d♂️',\n",
       " '🌈',\n",
       " '🐐',\n",
       " '💧',\n",
       " '🎬',\n",
       " '💍',\n",
       " '😣',\n",
       " '\\U0001f9e1',\n",
       " '🔵',\n",
       " '🌙',\n",
       " '\\U0001f92b',\n",
       " '🙌🏾',\n",
       " '😓',\n",
       " '📌',\n",
       " '🌷',\n",
       " '▪️',\n",
       " '🤢',\n",
       " '❄️',\n",
       " '➖',\n",
       " '🎈',\n",
       " '🎯',\n",
       " '💪🏽',\n",
       " '🤷🏼\\u200d♀️',\n",
       " '❣️',\n",
       " '🕑',\n",
       " '😚',\n",
       " '🇨🇦',\n",
       " '🇫🇷',\n",
       " '🥀',\n",
       " '💸',\n",
       " '🦋',\n",
       " '🌴',\n",
       " '💐',\n",
       " '🔞',\n",
       " '💌',\n",
       " '🥇',\n",
       " '💻',\n",
       " '🏀',\n",
       " '⬇',\n",
       " '🕙',\n",
       " '📈',\n",
       " '🤓',\n",
       " '👏🏽',\n",
       " '☑️',\n",
       " '🎮',\n",
       " '🌺',\n",
       " '1⃣',\n",
       " '🎊',\n",
       " '✌️',\n",
       " '💨',\n",
       " '🔁',\n",
       " '🤘',\n",
       " '💝',\n",
       " '🐝',\n",
       " '🇧🇷',\n",
       " '👌🏻',\n",
       " '🔊',\n",
       " '😲',\n",
       " '🇮🇹',\n",
       " '🌼',\n",
       " '🍻',\n",
       " '🇪🇸',\n",
       " '🎤',\n",
       " '💣',\n",
       " '📲',\n",
       " '🤝',\n",
       " '🌿',\n",
       " '🎨',\n",
       " '2⃣',\n",
       " '😹',\n",
       " '1️⃣',\n",
       " '🔱',\n",
       " '💪🏾',\n",
       " '😶',\n",
       " '🍁',\n",
       " '💩',\n",
       " '🆚',\n",
       " '📻',\n",
       " '💭',\n",
       " '⏳',\n",
       " '👍🏼',\n",
       " '2️⃣',\n",
       " '⭐',\n",
       " '📅',\n",
       " '🤑',\n",
       " '\\U0001f92f',\n",
       " '✊',\n",
       " '🐍',\n",
       " '📊',\n",
       " '🔸',\n",
       " '💟',\n",
       " '📝',\n",
       " '🇩🇪',\n",
       " '👌🏾',\n",
       " '🙋🏻\\u200d♀️',\n",
       " '🌏',\n",
       " '🐱',\n",
       " '🆒',\n",
       " '🙁',\n",
       " '💪🏻',\n",
       " '🌱',\n",
       " '🏴\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f',\n",
       " '🐻',\n",
       " '🐾',\n",
       " '🇮🇳',\n",
       " '📱',\n",
       " '📚',\n",
       " '3⃣',\n",
       " '✈',\n",
       " '🏁',\n",
       " '🦄',\n",
       " '✌',\n",
       " '😖',\n",
       " '💃',\n",
       " '🔄',\n",
       " '🦁',\n",
       " '👏🏾',\n",
       " '4⃣',\n",
       " '💬',\n",
       " '💤',\n",
       " '🤷\\u200d♀️',\n",
       " '👉🏻',\n",
       " '💪🏼',\n",
       " '☁',\n",
       " '😰',\n",
       " '🇰🇷',\n",
       " '👌🏼',\n",
       " '👏🏿',\n",
       " '🇿🇦',\n",
       " '👇🏻',\n",
       " '🍒',\n",
       " '\\U0001f92c',\n",
       " '😯',\n",
       " '🤷\\u200d♂️',\n",
       " '🇯🇵',\n",
       " '👻',\n",
       " '🇦🇷',\n",
       " '👋🏻',\n",
       " '🤠',\n",
       " '👌🏽',\n",
       " '🇦🇫',\n",
       " '😵',\n",
       " '🙊',\n",
       " '🎀',\n",
       " '⏩',\n",
       " '3️⃣',\n",
       " '🇵🇭',\n",
       " '🕰️',\n",
       " '🤕',\n",
       " '\\U0001f92e',\n",
       " '🇲🇽',\n",
       " '☘️',\n",
       " '☁️',\n",
       " '🤐',\n",
       " '🎼',\n",
       " '😷',\n",
       " '🤖',\n",
       " '🚫',\n",
       " '🤦🏼\\u200d♀️',\n",
       " '🌀',\n",
       " '🥂',\n",
       " '👇🏼',\n",
       " '🤞🏽',\n",
       " '🍓',\n",
       " '🤦\\u200d♂️',\n",
       " '📆',\n",
       " '✊🏾',\n",
       " '📰',\n",
       " '🔽',\n",
       " '🕊',\n",
       " '🤡',\n",
       " '🎸',\n",
       " '🔮',\n",
       " '🎓',\n",
       " '🚮',\n",
       " '🍯',\n",
       " '☑',\n",
       " '😠',\n",
       " '✋',\n",
       " '🗓',\n",
       " '😨',\n",
       " '♻️',\n",
       " '👊🏻',\n",
       " '📽️',\n",
       " '☝️',\n",
       " '🍕',\n",
       " '🤞',\n",
       " '🖥️',\n",
       " '👆',\n",
       " '🐺',\n",
       " '🔛',\n",
       " '🆕',\n",
       " '☠️',\n",
       " '🔑',\n",
       " '💡',\n",
       " '😙',\n",
       " '🏠',\n",
       " '🏡',\n",
       " '🤞🏾',\n",
       " '⤵️',\n",
       " '🇮🇩',\n",
       " '💁🏻\\u200d♀️',\n",
       " '🐇',\n",
       " '🇦🇺',\n",
       " '↪',\n",
       " '🍭',\n",
       " '🍆',\n",
       " '🕺',\n",
       " '🦅',\n",
       " '🇵🇷',\n",
       " '🇳🇬',\n",
       " '🇧🇭',\n",
       " '🍷',\n",
       " '▪',\n",
       " '💁',\n",
       " '✌🏻',\n",
       " '👐',\n",
       " '🍫',\n",
       " '🏃\\u200d♀️',\n",
       " '💿',\n",
       " '📖',\n",
       " '🇪🇬',\n",
       " '🤙',\n",
       " '🔆',\n",
       " '👽',\n",
       " '🏘',\n",
       " '🥊',\n",
       " '😗',\n",
       " '🍎',\n",
       " '👙',\n",
       " '☀',\n",
       " '🔝',\n",
       " '🌌',\n",
       " '🏈',\n",
       " '🤷🏼\\u200d♂️',\n",
       " '👶',\n",
       " '👉🏼',\n",
       " '🐑',\n",
       " '🇨🇳',\n",
       " '🍰',\n",
       " '✌🏼',\n",
       " '🍺',\n",
       " '🍾',\n",
       " '4️⃣',\n",
       " '5⃣',\n",
       " '🏳️\\u200d🌈',\n",
       " '😧',\n",
       " '🐦',\n",
       " '✍🏽',\n",
       " '💵',\n",
       " '🐧',\n",
       " '🏃',\n",
       " '☕',\n",
       " '🙏🏿',\n",
       " '👍🏽',\n",
       " '⏱',\n",
       " '⬅️',\n",
       " '🔙',\n",
       " '🐕',\n",
       " '😟',\n",
       " '🍊',\n",
       " '😿',\n",
       " '🤦\\u200d♀️',\n",
       " '🙋',\n",
       " '↗',\n",
       " '🛑',\n",
       " '🇱🇷',\n",
       " '🍋',\n",
       " '💁🏽\\u200d♀️',\n",
       " '⬆️',\n",
       " '✌🏽',\n",
       " '🎟',\n",
       " '🌵',\n",
       " '🍹',\n",
       " '🗓️',\n",
       " '🔃',\n",
       " '✳️',\n",
       " '❄',\n",
       " '🕒',\n",
       " '🤒',\n",
       " '✊🏽',\n",
       " '📽',\n",
       " '🍿',\n",
       " '🐸',\n",
       " '⚔️',\n",
       " '🤘🏼',\n",
       " '🗣️',\n",
       " '🐹',\n",
       " '🛫',\n",
       " '💢',\n",
       " '👎',\n",
       " '👁',\n",
       " '🐭',\n",
       " '🇹🇭',\n",
       " '✏️',\n",
       " '🔫',\n",
       " '😦',\n",
       " '👊🏼',\n",
       " '🏟',\n",
       " '🐷',\n",
       " '🗽',\n",
       " '🌐',\n",
       " '🍉',\n",
       " '🌳',\n",
       " '🤘🏻',\n",
       " '🐨',\n",
       " '🐢',\n",
       " '🌅',\n",
       " '📋',\n",
       " '✌🏾',\n",
       " '✍️',\n",
       " '👼',\n",
       " '🚧',\n",
       " '📀',\n",
       " '🤘🏽',\n",
       " '❣',\n",
       " '♠',\n",
       " '🆓',\n",
       " '👺',\n",
       " '🖕',\n",
       " '👊🏾',\n",
       " '❗',\n",
       " '☹',\n",
       " '👹',\n",
       " '🌲',\n",
       " '🎩',\n",
       " '❓',\n",
       " '🆘',\n",
       " '🇰🇪',\n",
       " '🇵🇰',\n",
       " '🇹🇷',\n",
       " '🤙🏼',\n",
       " '🐼',\n",
       " '↪️',\n",
       " '™',\n",
       " '🐲',\n",
       " '🥈',\n",
       " '🔐',\n",
       " '⚜️',\n",
       " '☄️',\n",
       " '🍌',\n",
       " '🐬',\n",
       " '🚗',\n",
       " '📦',\n",
       " '🇵🇪',\n",
       " '🤙🏽',\n",
       " '👇🏽',\n",
       " '🇲🇾',\n",
       " '👋🏼',\n",
       " '🦉',\n",
       " '🍩',\n",
       " '🏙',\n",
       " '🙀',\n",
       " '👄',\n",
       " '♠️',\n",
       " '📞',\n",
       " '💃🏻',\n",
       " '🦊',\n",
       " '\\U0001f995',\n",
       " '\\U0001f9e2',\n",
       " '5️⃣',\n",
       " '🐉',\n",
       " '👣',\n",
       " '💅',\n",
       " '👾',\n",
       " '😸',\n",
       " '🤙🏻',\n",
       " '🇷🇺',\n",
       " '💉',\n",
       " '🔷',\n",
       " '💊',\n",
       " '◀️',\n",
       " '🍔',\n",
       " '🌠',\n",
       " '😼',\n",
       " '💷',\n",
       " '👕',\n",
       " '🤞🏻',\n",
       " '👊🏽',\n",
       " '🐎',\n",
       " '🍇',\n",
       " '🥚',\n",
       " '👸',\n",
       " '🤞🏼',\n",
       " '🔎',\n",
       " '🗿',\n",
       " '🍍',\n",
       " '🍪',\n",
       " '✝️',\n",
       " '↘',\n",
       " '☮️',\n",
       " '👫',\n",
       " '👤',\n",
       " '🚲',\n",
       " '🤥',\n",
       " '🌝',\n",
       " '🏅',\n",
       " '➕',\n",
       " '👿',\n",
       " '😺',\n",
       " '🇵🇹',\n",
       " '💁🏼\\u200d♀️',\n",
       " '♦️',\n",
       " '👟',\n",
       " '💃🏽',\n",
       " '🤷🏿\\u200d♂️',\n",
       " '🌬',\n",
       " '📼',\n",
       " '⏪',\n",
       " '🚂',\n",
       " '🦇',\n",
       " '⤵',\n",
       " 'ℹ️',\n",
       " '🙌🏿',\n",
       " '🤷',\n",
       " '⬅',\n",
       " '🇵🇸',\n",
       " '🎲',\n",
       " '💶',\n",
       " '🇬🇭',\n",
       " '🤙🏾',\n",
       " '🍜',\n",
       " '😽',\n",
       " '🤘🏾',\n",
       " '🍦',\n",
       " '🥁',\n",
       " '🍼',\n",
       " '🔪',\n",
       " '🇮🇪',\n",
       " '👇🏾',\n",
       " '🍸',\n",
       " '🌧',\n",
       " '🇧🇪',\n",
       " '🌮',\n",
       " '🖨',\n",
       " '6️⃣',\n",
       " '▫️',\n",
       " '🍄',\n",
       " '🐈',\n",
       " '🍈',\n",
       " '🇨🇱',\n",
       " '🇳🇴',\n",
       " '🏝',\n",
       " '🎙',\n",
       " '\\U0001f996',\n",
       " '🗳️',\n",
       " '🚩',\n",
       " '\\U0001f91f🏽',\n",
       " '🐘',\n",
       " '🕷',\n",
       " '🌶',\n",
       " '🚌',\n",
       " '🌃',\n",
       " '🎭',\n",
       " '🥑',\n",
       " '🦈',\n",
       " '\\U0001f9e0',\n",
       " '🤦🏼\\u200d♂️',\n",
       " '🐒',\n",
       " '🔍',\n",
       " '✊🏼',\n",
       " '↩',\n",
       " '🙅🏾\\u200d♂️',\n",
       " '🐟',\n",
       " '🛎',\n",
       " '🔰',\n",
       " '🐜',\n",
       " '🧀',\n",
       " '👓',\n",
       " '⚫',\n",
       " '🗨',\n",
       " '👉🏾',\n",
       " '🍂',\n",
       " '🍥',\n",
       " '🕵🏼\\u200d♂',\n",
       " '🕐',\n",
       " '👢',\n",
       " '🅰️',\n",
       " '☔',\n",
       " '🏏',\n",
       " '✖️',\n",
       " '👗',\n",
       " '✏',\n",
       " '☝',\n",
       " '👍🏾',\n",
       " '🏖',\n",
       " '💑',\n",
       " '☄',\n",
       " '👉🏽',\n",
       " '🙇',\n",
       " '🆙',\n",
       " '👥',\n",
       " '🕘',\n",
       " '☎️',\n",
       " '🆔',\n",
       " '🦍',\n",
       " '🍬',\n",
       " '🎇',\n",
       " '🔌',\n",
       " '☝🏻',\n",
       " '🍟',\n",
       " '🥉',\n",
       " '💁\\u200d♀️',\n",
       " '🐴',\n",
       " '💈',\n",
       " '🎙️',\n",
       " '🤦',\n",
       " '⚾',\n",
       " '🏒',\n",
       " '👶🏻',\n",
       " '🙆',\n",
       " '🌪',\n",
       " '🇸🇾',\n",
       " '🐙',\n",
       " '♦',\n",
       " '🏹',\n",
       " '🇸🇪',\n",
       " '⛔',\n",
       " '☝🏾',\n",
       " '🛌',\n",
       " '✂️',\n",
       " '↗️',\n",
       " '🔺',\n",
       " '✊🏻',\n",
       " '👧',\n",
       " '🙋🏽\\u200d♀️',\n",
       " '🖐',\n",
       " '🏄🏻\\u200d♀️',\n",
       " '\\U0001f6f8',\n",
       " '⚪',\n",
       " '🇳🇱',\n",
       " '🍳',\n",
       " '\\U0001f91f',\n",
       " '🤳',\n",
       " '🎆',\n",
       " '✒',\n",
       " '⭕',\n",
       " '🆗',\n",
       " '👋🏽',\n",
       " '👐🏽',\n",
       " '\\U0001f964',\n",
       " '💠',\n",
       " '🏌',\n",
       " '🎹',\n",
       " '💅🏽',\n",
       " '💁🏾\\u200d♀️',\n",
       " '🏎',\n",
       " '🏉',\n",
       " '💃🏼',\n",
       " '🐌',\n",
       " '🥃',\n",
       " '📩',\n",
       " '🚬',\n",
       " '🤦🏿\\u200d♂️',\n",
       " '🍐',\n",
       " '💼',\n",
       " '🏇',\n",
       " '🍵',\n",
       " '🥋',\n",
       " '🔂',\n",
       " '❎',\n",
       " '🖕🏽',\n",
       " '🔨',\n",
       " '📡',\n",
       " '🇮🇱',\n",
       " '🏴\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f',\n",
       " '🖕🏾',\n",
       " '👁️',\n",
       " '⚖️',\n",
       " '✴',\n",
       " '🇪🇺',\n",
       " '🚚',\n",
       " '🖇',\n",
       " '7️⃣',\n",
       " '\\U0001f91f🏾',\n",
       " '🎰',\n",
       " '📉',\n",
       " '🔟',\n",
       " '🇨🇴',\n",
       " '🇳🇿',\n",
       " '☝🏽',\n",
       " '💅🏼',\n",
       " '💅🏾',\n",
       " '🏃\\u200d♂️',\n",
       " '🐀',\n",
       " '🐛',\n",
       " '🥔',\n",
       " '🌤',\n",
       " '📨',\n",
       " '🌾',\n",
       " '🍏',\n",
       " '👸🏻',\n",
       " '🐊',\n",
       " '🦎',\n",
       " '🕕',\n",
       " '🎞',\n",
       " '🇬🇷',\n",
       " '⁉️',\n",
       " '👼🏽',\n",
       " '☘',\n",
       " '🎾',\n",
       " '🚿',\n",
       " '‼',\n",
       " '🚔',\n",
       " '🏟️',\n",
       " '🎄',\n",
       " '🔻',\n",
       " '🏴\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f',\n",
       " '🐤',\n",
       " '🎱',\n",
       " '🙆🏼\\u200d♂️',\n",
       " '🐳',\n",
       " '🍗',\n",
       " '🚘',\n",
       " '🎟️',\n",
       " '🖥',\n",
       " '💅🏿',\n",
       " '↩️',\n",
       " '®',\n",
       " '🇯🇲',\n",
       " '\\U0001f91f🏼',\n",
       " '🐠',\n",
       " '🙉',\n",
       " '🚪',\n",
       " '☠',\n",
       " '🙅🏽\\u200d♀️',\n",
       " '🙋\\u200d♀️',\n",
       " '🕺🏽',\n",
       " '🏐',\n",
       " '👰',\n",
       " '🕺🏻',\n",
       " '🦆',\n",
       " '🍨',\n",
       " '🎡',\n",
       " '📂',\n",
       " '👇🏿',\n",
       " '🐋',\n",
       " '🥓',\n",
       " '🏰',\n",
       " '💳',\n",
       " '⛓',\n",
       " '♻',\n",
       " '👋🏾',\n",
       " '🖕🏻',\n",
       " '👂🏾',\n",
       " '👯\\u200d♀️',\n",
       " '🚴',\n",
       " '🍝',\n",
       " '🚦',\n",
       " '👔',\n",
       " '⌨️',\n",
       " '〽️',\n",
       " '🇵🇱',\n",
       " '🚶',\n",
       " '🐄',\n",
       " '🌋',\n",
       " '🌄',\n",
       " '↘️',\n",
       " '9️⃣',\n",
       " '🇺🇬',\n",
       " '👩',\n",
       " '👸🏼',\n",
       " '👬',\n",
       " '🍞',\n",
       " '🎃',\n",
       " '💃🏾',\n",
       " '🐽',\n",
       " '🦃',\n",
       " '🥕',\n",
       " '🎖',\n",
       " '🔶',\n",
       " '🐔',\n",
       " '🌭',\n",
       " '⛪',\n",
       " '🇿🇼',\n",
       " '☝🏼',\n",
       " '🗺',\n",
       " '⏱️',\n",
       " '🕖',\n",
       " '🎒',\n",
       " '😾',\n",
       " '🤴',\n",
       " '🐅',\n",
       " '🥗',\n",
       " '🍽',\n",
       " '🍴',\n",
       " '🌪️',\n",
       " '👭',\n",
       " '🐞',\n",
       " '♨',\n",
       " '🚁',\n",
       " '⛱',\n",
       " '🛏',\n",
       " '🔓',\n",
       " '👂',\n",
       " '👯',\n",
       " '⌚',\n",
       " '🥅',\n",
       " '💴',\n",
       " '👆🏼',\n",
       " '👎🏽',\n",
       " '\\U0001f9df\\u200d♂️',\n",
       " '🐆',\n",
       " '🐮',\n",
       " '🎪',\n",
       " '🕶',\n",
       " '🔼',\n",
       " '📛',\n",
       " '👎🏼',\n",
       " '🕶️',\n",
       " '✂',\n",
       " '🇸🇬',\n",
       " '🖕🏼',\n",
       " '🃏',\n",
       " '👖',\n",
       " '✊🏿',\n",
       " '💁🏻',\n",
       " '💁🏼',\n",
       " '⚒',\n",
       " '◻️',\n",
       " '◾',\n",
       " '🇦🇲',\n",
       " '🏍️',\n",
       " '🚢',\n",
       " '☣',\n",
       " '◀',\n",
       " '🏴',\n",
       " '💮',\n",
       " '🥜',\n",
       " '🍣',\n",
       " '🦑',\n",
       " '🔦',\n",
       " '8️⃣',\n",
       " '🐵',\n",
       " '🦌',\n",
       " '🌯',\n",
       " '🎣',\n",
       " '\\U0001f9e5',\n",
       " '⚰️',\n",
       " '✋🏻',\n",
       " '\\U0001f91f🏻',\n",
       " '👎🏻',\n",
       " '👐🏾',\n",
       " '💁🏻\\u200d♂️',\n",
       " '🥝',\n",
       " '🛬',\n",
       " '⛈',\n",
       " '⛱️',\n",
       " '⬆',\n",
       " '⚛️',\n",
       " '💲',\n",
       " '🏴\\u200d☠️',\n",
       " '🇿🇲',\n",
       " '👌🏿',\n",
       " '🙅',\n",
       " '👸🏽',\n",
       " '🍅',\n",
       " '💽',\n",
       " '🛒',\n",
       " '🇸🇳',\n",
       " '🙋🏼\\u200d♀️',\n",
       " '🐓',\n",
       " '⛅',\n",
       " '🕹️',\n",
       " '🔈',\n",
       " '🇨🇭',\n",
       " '🏊',\n",
       " '💏',\n",
       " '🕸',\n",
       " '🌇',\n",
       " '✉',\n",
       " '❕',\n",
       " '✴️',\n",
       " '🖖',\n",
       " '👎🏾',\n",
       " '💪🏿',\n",
       " '🙇🏽\\u200d♀️',\n",
       " '🌽',\n",
       " '🔋',\n",
       " '🎗',\n",
       " '🛍',\n",
       " '🛋️',\n",
       " '🅱️',\n",
       " '🇦🇪',\n",
       " '🇫🇮',\n",
       " '🇾🇪',\n",
       " '👐🏻',\n",
       " '👸🏾',\n",
       " '🚙',\n",
       " '🤚',\n",
       " '👩🏻',\n",
       " '🙆🏻\\u200d♀️',\n",
       " '🙋\\u200d♂️',\n",
       " '🙇\\u200d♀️',\n",
       " '🐖',\n",
       " '🐏',\n",
       " '🦀',\n",
       " '❇️',\n",
       " '💅🏻',\n",
       " '💁🏼\\u200d♂️',\n",
       " '🕊️',\n",
       " '🥘',\n",
       " '⛳',\n",
       " ...]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sort_freq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('👍', 0.5708750486373901),\n",
       " ('😉', 0.5507802963256836),\n",
       " ('😁', 0.5429814457893372),\n",
       " ('⭐️i', 0.5380228757858276),\n",
       " ('awesom', 0.5341282486915588),\n",
       " ('😅', 0.5143481492996216),\n",
       " ('🤗', 0.5049486756324768),\n",
       " ('😏', 0.503909707069397),\n",
       " ('😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂', 0.4923427402973175),\n",
       " ('😘', 0.4906120002269745),\n",
       " ('wonder', 0.48665982484817505),\n",
       " ('goan', 0.4851222038269043),\n",
       " ('jeanett', 0.47811296582221985),\n",
       " ('skyrim', 0.4774525463581085),\n",
       " ('🙀🙀🙀', 0.47732964158058167),\n",
       " ('😊', 0.47706007957458496),\n",
       " ('👍👊', 0.4713195264339447),\n",
       " ('carsss', 0.47071343660354614),\n",
       " ('😍thank', 0.4696727693080902),\n",
       " ('💞🌺💕', 0.4684681296348572)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar('😀',topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_prodictor('happi', model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_pipeline(sentense):\n",
    "    out = [word for word in sentense.lower().split(\" \") if word not in stop]\n",
    "    out = [snowball.stem(word) for word in out]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentense = \"under\"\n",
    "[word for word in sentense.lower().split(\" \") if word not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pipeline(sentense)model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'😀'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_prodictor('us', model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'🚌'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_prodictor('nyc', model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "# Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.16235446313065977, 0.21978984238178634),\n",
       " (0.2128072445019405, 0.2634107285828663))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original scores\n",
    "score1[0:2],score2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word=\"happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = model1.most_similar(word,topn=75)\n",
    "sim.extend(model2.most_similar(word,topn=75))\n",
    "sim = pd.DataFrame(sim).sort_values(by=1, ascending=False).set_index(0).to_dict()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = pd.DataFrame(sim).sort_values(by=1, ascending=False).set_index(0).to_dict()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble by combine the correlations list\n",
    "def ensemble_emoji_prodictor(word, model1, model2):\n",
    "    sim = model1.most_similar(word,topn=75)\n",
    "    sim.extend(model2.most_similar(word,topn=75))\n",
    "    sim = pd.DataFrame(sim).sort_values(by=1, ascending=False).set_index(0).to_dict()[1]\n",
    "    \n",
    "    for i in sim:\n",
    "        if i in emoji_list:\n",
    "            return i\n",
    "               \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define score function \n",
    "def word2vec_score_emsemble(val_dict,model1, model2):\n",
    "    total_words = 0\n",
    "    total_predicts = 0\n",
    "    correct = 0\n",
    "    words = []\n",
    "    word_vectors = model1.wv\n",
    "    for word in val_dict:\n",
    "#         print(word)\n",
    "        if word:\n",
    "            w = word.lower()\n",
    "            words.append(w)\n",
    "            if w in word_vectors:\n",
    "                total_words += 1\n",
    "                pred = ensemble_emoji_prodictor(w, model1, model2)\n",
    "                if pred in val_dict[word]:\n",
    "                    correct += 1\n",
    "                    total_predicts += 1\n",
    "                elif pred in emoji_set:\n",
    "                    total_predicts += 1\n",
    "    return correct/total_words, correct/total_predicts, words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.20633893919793014, 0.22592067988668554)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_score_emsemble(val_dict,model1, model2)[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensemble the correlation doesnot work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble by combine the correlations list\n",
    "def ensemble_emoji_prodictor(word, model1, model2, thres):\n",
    "    p1 = emoji_prodictor(word, model1)\n",
    "    p2 = emoji_prodictor(word, model2)\n",
    "    t = int(thres*non_zero_count)\n",
    "    l1 = list(sort_freq.keys())[:t]\n",
    "    l2 = list(sort_freq.keys())[t:]\n",
    "    if p1 in l1:\n",
    "        return p1\n",
    "    else:\n",
    "        return p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define score function \n",
    "def word2vec_score_emsemble(val_dict,model1, model2, thres):\n",
    "    total_words = 0\n",
    "    total_predicts = 0\n",
    "    correct = 0\n",
    "    words = []\n",
    "    word_vectors = model1.wv\n",
    "    for word in val_dict:\n",
    "#         print(word)\n",
    "        if word:\n",
    "            w = word.lower()\n",
    "            words.append(w)\n",
    "            if w in word_vectors:\n",
    "                total_words += 1\n",
    "                pred = ensemble_emoji_prodictor(w, model1, model2, thres)\n",
    "                if pred in val_dict[word]:\n",
    "                    correct += 1\n",
    "                    total_predicts += 1\n",
    "                elif pred in emoji_set:\n",
    "                    total_predicts += 1\n",
    "    return correct/total_words, correct/total_predicts, words\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17658473479948253, 0.2161520190023753)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_score_emsemble(val_dict,model1, model2, 0.5)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55,\n",
       "       0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thres_arr = np.linspace(0.05,0.95,19);thres_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05 (0.21733505821474774, 0.24651504035216434)\n",
      "0.1 (0.2166882276843467, 0.2501867064973861)\n",
      "0.15 (0.2147477360931436, 0.25018839487565936)\n",
      "0.2 (0.2089262613195343, 0.24506828528072838)\n",
      "0.25 (0.20310478654592498, 0.2389649923896499)\n",
      "0.3 (0.19728331177231564, 0.23318042813455658)\n",
      "0.35 (0.18952134540750323, 0.22608024691358025)\n",
      "0.39999999999999997 (0.18628719275549807, 0.223950233281493)\n",
      "0.44999999999999996 (0.18305304010349288, 0.22092115534738485)\n",
      "0.49999999999999994 (0.17658473479948253, 0.2161520190023753)\n",
      "0.5499999999999999 (0.17270375161707632, 0.21445783132530122)\n",
      "0.6 (0.17076326002587322, 0.21782178217821782)\n",
      "0.65 (0.1649417852522639, 0.21982758620689655)\n",
      "0.7 (0.1630012936610608, 0.2202797202797203)\n",
      "0.75 (0.1630012936610608, 0.2204724409448819)\n",
      "0.7999999999999999 (0.16235446313065977, 0.21978984238178634)\n",
      "0.85 (0.16235446313065977, 0.21978984238178634)\n",
      "0.9 (0.16235446313065977, 0.21978984238178634)\n",
      "0.95 (0.16235446313065977, 0.21978984238178634)\n"
     ]
    }
   ],
   "source": [
    "# if p2 in l2\n",
    "for thres in thres_arr:\n",
    "    print(thres, word2vec_score_emsemble(val_dict,model1, model2, thres)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 (0.21410090556274256, 0.26501200960768617)\n",
      "0.02 (0.21539456662354464, 0.266613290632506)\n",
      "0.03 (0.21539456662354464, 0.26618705035971224)\n",
      "0.04 (0.21539456662354464, 0.26618705035971224)\n",
      "0.05 (0.21604139715394566, 0.266986410871303)\n",
      "0.060000000000000005 (0.21798188874514876, 0.2687400318979266)\n",
      "0.06999999999999999 (0.21798188874514876, 0.2685258964143426)\n",
      "0.08 (0.21798188874514876, 0.2680986475735879)\n",
      "0.09 (0.21733505821474774, 0.2670906200317965)\n",
      "0.09999999999999999 (0.21733505821474774, 0.26666666666666666)\n",
      "0.11 (0.21733505821474774, 0.26645519429024583)\n",
      "0.12 (0.21733505821474774, 0.26645519429024583)\n",
      "0.13 (0.2166882276843467, 0.2654516640253566)\n",
      "0.14 (0.21733505821474774, 0.26540284360189575)\n",
      "0.15000000000000002 (0.21733505821474774, 0.26498422712933756)\n",
      "0.16 (0.21604139715394566, 0.2623723487824038)\n",
      "0.17 (0.2166882276843467, 0.2619233776387803)\n",
      "0.18000000000000002 (0.21539456662354464, 0.26015625)\n",
      "0.19 (0.21604139715394566, 0.2595182595182595)\n",
      "0.2 (0.2166882276843467, 0.26009316770186336)\n"
     ]
    }
   ],
   "source": [
    "# if p1 in l1\n",
    "thres_arr = np.linspace(0.01,0.20,20)\n",
    "for thres in thres_arr:\n",
    "    print(thres, word2vec_score_emsemble(val_dict,model1, model2, thres)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((0.16235446313065977, 0.21978984238178634),\n",
    " (0.2128072445019405, 0.2634107285828663))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.267386829730014"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model1, emoji_frequency)    # CBOW good at predicting more frequent word (high weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06241611360445485"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score(val_dict, model2, emoji_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_weighted_score_ensemble(val_dict, model1, model2, thres, emoji_frequency):\n",
    "    total_words = 0\n",
    "    total_weighted = 0\n",
    "    correct_weighted = 0\n",
    "#     words = []\n",
    "    word_vectors = model1.wv\n",
    "    for word in val_dict:\n",
    "        if word:\n",
    "            w = word.lower()\n",
    "#             words.append(w)\n",
    "            if w in word_vectors:\n",
    "                total_words += 1\n",
    "                prediction = ensemble_emoji_prodictor(w, model1, model2, thres)\n",
    "                if prediction in val_dict[word]:\n",
    "                    correct_weighted += emoji_frequency[prediction]\n",
    "                    total_weighted += emoji_frequency[prediction]\n",
    "                elif prediction in emoji_set:\n",
    "                    total_weighted += emoji_frequency[prediction]\n",
    "    return correct_weighted/total_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09934862490553567"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_weighted_score_ensemble(val_dict, model1, model2, 0.06, emoji_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08474481924748074\n",
      "0.09006502653848159\n",
      "0.09479537639495465\n",
      "0.09471136964476934\n",
      "0.09519971373942336\n",
      "0.09934862490553567\n",
      "0.10045718196569688\n",
      "0.10347345581361085\n",
      "0.10329134014169694\n",
      "0.10327865628196051\n",
      "0.10330389100633897\n",
      "0.10388116539603176\n",
      "0.10619495618015533\n",
      "0.10655389009358177\n",
      "0.11036054258964167\n",
      "0.11017199038168167\n",
      "0.11088114427920304\n",
      "0.11100778048100647\n",
      "0.11247291178759795\n",
      "0.11263821026961353\n"
     ]
    }
   ],
   "source": [
    "# if p1 in l1\n",
    "thres_arr = np.linspace(0.01,0.20,20)\n",
    "for thres in thres_arr:\n",
    "    print(word2vec_weighted_score_ensemble(val_dict, model1, model2, thres, emoji_frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"Head shoulders knees and toes knees and toes\"\n",
    "s2 = \"And eyes and ears and mouth and mouth and nose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "shoulders\n",
      "knees\n",
      "😊\n",
      "🍆\n",
      "knees\n",
      "😊\n",
      "🍆\n",
      "😊\n",
      "eyes\n",
      "😊\n",
      "ears\n",
      "😊\n",
      "🍆\n",
      "😊\n",
      "🍆\n",
      "😊\n",
      "nose\n"
     ]
    }
   ],
   "source": [
    "for w in s1.lower().split(\" \"):\n",
    "    print(emoji_prodictor(w, model1))\n",
    "for w in s2.lower().split(\" \"):\n",
    "    print(emoji_prodictor(w, model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "💁🏾\n",
      "🙇🏽‍♀️\n",
      "😂\n",
      "💅\n",
      "🙇🏽‍♀️\n",
      "😂\n",
      "💅\n",
      "😂\n",
      "eyes\n",
      "😂\n",
      "ears\n",
      "😂\n",
      "🙇🏾‍♀️\n",
      "😂\n",
      "🙇🏾‍♀️\n",
      "😂\n",
      "nose\n"
     ]
    }
   ],
   "source": [
    "for w in s1.lower().split(\" \"):\n",
    "    print(emoji_prodictor(w, model2))\n",
    "for w in s2.lower().split(\" \"):\n",
    "    print(emoji_prodictor(w, model2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "# RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length 5835178\n",
      "total chars:  2338\n"
     ]
    }
   ],
   "source": [
    "with open('emoji_100k.txt', 'r') as file:\n",
    "    text = file.read().lower()\n",
    "print('text length', len(text))\n",
    "chars = sorted(list(set(text))) # getting all unique chars\n",
    "print('total chars: ', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN model not working here since RNN requires a large X matrix, with 3 dimension as (num_of_lines * window_size * num_of_chars)\n",
    "Since we have a very large num_of_char and lots of num_of_lines. It requires hundreds of gigabytes memory to run each for a small sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 169. GiB for an array with shape (1945046, 40, 2338) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-00250b46519c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msentences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnext_chars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 169. GiB for an array with shape (1945046, 40, 2338) and data type bool"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = \"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
    "                             verbose=1, save_best_only=True,\n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)\n",
    "callbacks = [print_callback, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, batch_size=128, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, diversity):\n",
    "    # Get random starting text\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(500, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "s= \"👍\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'👍'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
